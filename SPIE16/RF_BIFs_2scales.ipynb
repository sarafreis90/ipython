{
 "metadata": {
  "name": "",
  "signature": "sha256:17c040f0e50f303056b064e9c7ba1bbc14a79608764ab02095fd29f333c80ff9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nibabel as nib\n",
      "import numpy as np\n",
      "import scipy.ndimage\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "import matplotlib as mpl\n",
      "from scipy import stats\n",
      "from scipy import ndimage\n",
      "import glob\n",
      "import csv\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import plotly.plotly as py\n",
      "from plotly.graph_objs import *\n",
      "from pylab import *\n",
      "import cv2\n",
      "\n",
      "\n",
      "import sklearn\n",
      "from sklearn import svm\n",
      "from sklearn import datasets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###---------------------------------------------------------###\n",
      "###-----If feature vector is saved in csv, start here-------###\n",
      "###---------------------------------------------------------###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-------Split data into training + test sets--------###\n",
      "def split_data(feature_vector):\n",
      "    \n",
      "    y_labels = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(1,), dtype = int)\n",
      "    z_names = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "    \n",
      "    E1 = []\n",
      "    csvOpen = open(feature_vector)\n",
      "    csvOpen.readline()  # skip the header\n",
      "    LBPreader = csv.reader(csvOpen)\n",
      "    for row in LBPreader:\n",
      "        E1.append(row)\n",
      "    \n",
      "    X_array_features = np.array(E1)\n",
      "    print X_array_features.shape\n",
      "\n",
      "    n_sample = len(X_array_features)\n",
      "    print n_sample\n",
      "\n",
      "    np.random.seed(0)\n",
      "    order = np.random.permutation(n_sample)\n",
      "    X_features = X_array_features[order]\n",
      "    y_labels = y_labels[order].astype(np.float)\n",
      "    z_names = z_names[order]\n",
      "    \n",
      "\n",
      "    X_train = X_features[:.7 * n_sample] ## select 70% of the data to train\n",
      "    y_train = y_labels[:.7 * n_sample]\n",
      "    z_train = z_names[:.7 * n_sample]\n",
      "    X_test = X_features[.7 * n_sample:]\n",
      "    y_test = y_labels[.7 * n_sample:]\n",
      "    z_test = z_names[.7 * n_sample:]\n",
      "    \n",
      "    print \"Test set:\" \n",
      "    print z_test\n",
      "\n",
      "    print \"Training set:\"\n",
      "    print z_train\n",
      "    \n",
      "    \n",
      "    return X_train, y_train, z_train, X_test, y_test, z_test\n",
      "\n",
      "link = '/Volumes/vph-prism5/Sara/SPIE16/BIFs_experiments/BIFs_2scales.csv'\n",
      "X_train_E1, y_train_E1, z_train_E1, X_test_E1, y_test_E1, z_test_E1 = split_data(link)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "rf = rf.fit(X_train_E1, y_train_E1)\n",
      "\n",
      "print y_test_E1\n",
      "rf.predict(X_test_E1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}