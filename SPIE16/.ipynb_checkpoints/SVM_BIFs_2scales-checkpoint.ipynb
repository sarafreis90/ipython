{
 "metadata": {
  "name": "",
  "signature": "sha256:f9a2b30fbedd3a459adce4994d95afe7e375279725f5e55e7187142c2e7ae9d5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nibabel as nib\n",
      "import numpy as np\n",
      "import scipy.ndimage\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "import matplotlib as mpl\n",
      "from scipy import stats\n",
      "from scipy import ndimage\n",
      "import glob\n",
      "import csv\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import plotly.plotly as py\n",
      "from plotly.graph_objs import *\n",
      "from pylab import *\n",
      "import cv2\n",
      "\n",
      "\n",
      "import sklearn\n",
      "from sklearn import svm\n",
      "from sklearn import datasets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###---------------------------------------------------------###\n",
      "###-----If feature vector is saved in csv, start here-------###\n",
      "###---------------------------------------------------------###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-------Split data into training + test sets--------###\n",
      "def split_data(feature_vector):\n",
      "    \n",
      "    y_labels = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(1,), dtype = int)\n",
      "    z_names = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "    \n",
      "    E1 = []\n",
      "    csvOpen = open(feature_vector)\n",
      "    csvOpen.readline()  # skip the header\n",
      "    LBPreader = csv.reader(csvOpen)\n",
      "    for row in LBPreader:\n",
      "        E1.append(row)\n",
      "    \n",
      "    X_array_features = np.array(E1)\n",
      "    print X_array_features.shape\n",
      "\n",
      "    n_sample = len(X_array_features)\n",
      "    print n_sample\n",
      "\n",
      "    np.random.seed(0)\n",
      "    order = np.random.permutation(n_sample)\n",
      "    X_features = X_array_features[order]\n",
      "    y_labels = y_labels[order].astype(np.float)\n",
      "    z_names = z_names[order]\n",
      "    \n",
      "\n",
      "    X_train = X_features[:.7 * n_sample] ## select 70% of the data to train\n",
      "    y_train = y_labels[:.7 * n_sample]\n",
      "    z_train = z_names[:.7 * n_sample]\n",
      "    X_test = X_features[.7 * n_sample:]\n",
      "    y_test = y_labels[.7 * n_sample:]\n",
      "    z_test = z_names[.7 * n_sample:]\n",
      "    \n",
      "    print \"Test set:\" \n",
      "    print z_test\n",
      "\n",
      "    print \"Training set:\"\n",
      "    print z_train\n",
      "    \n",
      "    \n",
      "    return X_train, y_train, z_train, X_test, y_test, z_test\n",
      "\n",
      "link = '/Volumes/vph-prism5/Sara/SPIE16/BIFs_experiments/BIFs_2scales.csv'\n",
      "X_train_E1, y_train_E1, z_train_E1, X_test_E1, y_test_E1, z_test_E1 = split_data(link)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(130, 14)\n",
        "130\n",
        "Test set:\n",
        "['18_01_m' '37_01_m' '30_01_m' '44_01_i' '44_03_i' '28_03_m' '25_01_m'\n",
        " '29_01_m' '09_05_i' '42_02_i' '26_02_i' '28_01_i' '11_01_i' '14_03_i'\n",
        " '29_02_i' '41_04_i' '17_01_i' '44_02_i' '15_02_i' '36_01_i' '22_04_i'\n",
        " '20_01_i' '06_04_m' '40_02_i' '31_05_m' '25_03_m' '31_04_m' '14_02_i'\n",
        " '39_03_i' '09_06_i' '30_02_m' '05_03_i' '36_02_i' '43_03_m' '42_03_i'\n",
        " '23_02_i' '22_03_i' '40_04_i' '17_02_i']\n",
        "Training set:\n",
        "['05_02_i' '20_02_i' '33_03_i' '36_03_i' '34_05_i' '12_01_i' '16_03_m'\n",
        " '13_02_i' '22_02_i' '11_02_i' '26_03_m' '05_01_i' '10_01_i' '36_04_i'\n",
        " '06_01_m' '17_03_i' '43_02_m' '33_01_m' '02_01_i' '34_01_i' '18_04_m'\n",
        " '34_04_i' '10_03_i' '18_03_m' '18_02_m' '15_03_m' '42_01_i' '23_04_i'\n",
        " '23_01_i' '08_03_i' '21_03_i' '41_05_m' '06_05_m' '27_03_i' '28_02_i'\n",
        " '16_04_m' '08_02_i' '33_02_m' '40_03_i' '34_03_i' '02_02_i' '16_02_m'\n",
        " '03_02_i' '31_01_m' '19_02_m' '35_02_i' '34_02_m' '39_02_i' '21_02_i'\n",
        " '37_03_i' '26_01_m' '11_03_i' '09_03_m' '37_02_m' '06_02_m' '43_01_m'\n",
        " '38_02_m' '15_04_i' '31_03_m' '21_01_m' '01_02_i' '19_04_m' '34_06_m'\n",
        " '39_01_i' '16_01_i' '02_03_i' '09_02_m' '15_01_m' '03_01_i' '19_01_m'\n",
        " '41_01_m' '35_04_i' '01_01_i' '13_03_i' '11_04_i' '19_03_m' '27_01_m'\n",
        " '14_01_i' '10_02_i' '26_04_m' '12_02_i' '31_02_m' '19_05_m' '35_03_i'\n",
        " '38_03_i' '13_01_i' '37_04_i' '08_01_i' '32_02_m' '09_04_m' '11_05_i']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-------Run SVM classifier--------###\n",
      "\n",
      "C=[]\n",
      "gamma=[]\n",
      "#for i in range(21): C.append(10.0**(i-5))\n",
      "#for i in range(17): gamma.append(10**(i-14))\n",
      "\n",
      "for i in range(2): C.append(10.0**(i-1)) #6\n",
      "for i in range(2): gamma.append(10**(i-5)) #5\n",
      "    \n",
      "print C\n",
      "print gamma\n",
      "\n",
      "###-----------------------------------------------------------###\n",
      "#---------- Set the parameters by cross-validation -----------###\n",
      "###-----------------------------------------------------------###\n",
      "\n",
      "def SVM_parameters(X_train, y_train, X_test, y_test):\n",
      "    \n",
      "    '''\n",
      "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
      "                         'C': [1, 10, 100, 1000]},\n",
      "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "    '''\n",
      "\n",
      "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
      "                         'C': C},\n",
      "                        {'kernel': ['linear'], 'C': C}]\n",
      "\n",
      "    #scores = ['precision', 'recall']\n",
      "    scores = ['accuracy'] # optimize for accuracy rather than precision or recall, or for F1 if you have a situation with unbalanced classes.\n",
      "\n",
      "    dict_params = {}\n",
      "    print \"Cross-validation for multi-scale LightLines:\"\n",
      "    print(\"\")\n",
      "    for score in scores:\n",
      "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "\n",
      "        clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
      "                           scoring='%s' % score)\n",
      "        clf.fit(X_train, y_train)\n",
      "\n",
      "        print(\"Best parameters set found on development set:\")\n",
      "        print(\"\")\n",
      "        print(clf.best_params_)\n",
      "        dict_params = clf.best_params_\n",
      "        \n",
      "        print(\"Grid scores on development set:\")\n",
      "        print(\"\")\n",
      "        for params, mean_score, scores in clf.grid_scores_:\n",
      "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "                  % (mean_score, scores.std() * 2, params))\n",
      "        print(\"\")\n",
      "\n",
      "        print(\"Detailed classification report (Multi-scale LightLines):\")\n",
      "        print(\"\")\n",
      "        print(\"The model is trained on the full development set.\")\n",
      "        print(\"The scores are computed on the full evaluation set.\")\n",
      "        print()\n",
      "        y_true, y_pred = y_test, clf.predict(X_test)\n",
      "        print(classification_report(y_true, y_pred))\n",
      "        print(\"\")\n",
      "        print(\"Confusion matrix\")\n",
      "        print(confusion_matrix(y_test, y_pred))\n",
      "        print(\"\")\n",
      "        \n",
      "        \n",
      "        return dict_params\n",
      "    \n",
      "##--------------------------------------------------------##\n",
      "##-----------------------ROC curves-----------------------##\n",
      "##--------------------------------------------------------##\n",
      "\n",
      "def SVM_classifier(X_train, y_train, X_test, y_test, SVM_param):\n",
      "    print \"True binary classification:\"\n",
      "    print y_test\n",
      "    ##----------------------------------##\n",
      "    ##--------- LighLines LBP ----------##\n",
      "    ##----------------------------------##\n",
      "    if len(SVM_param)==3:\n",
      "        print \"Non-linear SVM\"\n",
      "        print \" \"\n",
      "        clf_LBP = svm.SVC(C=SVM_param['C'], kernel=SVM_param['kernel'], gamma=SVM_param['gamma'])\n",
      "        \n",
      "    else:\n",
      "        print \"Linear SVM\"\n",
      "        print \" \"\n",
      "        clf_LBP = svm.SVC(C=SVM_param['C'], kernel=SVM_param['kernel'])\n",
      "    \n",
      "    y_score = clf_LBP.fit(X_train, y_train).decision_function(X_test)\n",
      "\n",
      "    print \"Predicted LBP:\"\n",
      "    print clf_LBP.predict(X_test)\n",
      "\n",
      "    # Compute ROC curve and ROC area \n",
      "    fpr_LBP, tpr_LBP, _ = roc_curve(y_test, y_score)\n",
      "    roc_auc_LBP = auc(fpr_LBP, tpr_LBP)\n",
      "\n",
      "    # Plot of a ROC curve for a specific class\n",
      "    plt.plot(fpr_LBP, tpr_LBP, label='LBP (BIF) (AUC = %0.2f)' % roc_auc_LBP)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')\n",
      "    \n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.05])\n",
      "    plt.xlabel('False Positive Rate')\n",
      "    plt.ylabel('True Positive Rate')\n",
      "    #plt.title('Receiver operating characteristic')\n",
      "    plt.legend(loc=\"lower right\",prop={'size':9.5})\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.1, 1.0]\n",
        "[1e-05, 0.0001]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SVM_param_E1 = SVM_parameters(X_train_E1, y_train_E1, X_test_E1, y_test_E1)\n",
      "#SVM_classifier(X_train_E1, y_train_E1, X_test_E1, y_test_E1, SVM_param_E1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cross-validation for multi-scale LightLines:\n",
        "\n",
        "# Tuning hyper-parameters for accuracy\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-21-01475cb7e541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSVM_param_E1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_E1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_E1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_E1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_E1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#SVM_classifier(X_train_E1, y_train_E1, X_test_E1, y_test_E1, SVM_param_E1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-20-a7035ae7a07c>\u001b[0m in \u001b[0;36mSVM_parameters\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     39\u001b[0m         clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n\u001b[1;32m     40\u001b[0m                            scoring='%s' % score)\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \"\"\"\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m                 for train, test in cv)\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}