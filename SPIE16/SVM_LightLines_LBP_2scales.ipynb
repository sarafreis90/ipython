{
 "metadata": {
  "name": "",
  "signature": "sha256:246a676c72ed4d384f35d39e800d9a4a09fd9a14384624a5c055514ae5f443b8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nibabel as nib\n",
      "import numpy as np\n",
      "import scipy.ndimage\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "import matplotlib as mpl\n",
      "from scipy import stats\n",
      "from scipy import ndimage\n",
      "import glob\n",
      "import csv\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import sys\n",
      "import plotly.plotly as py\n",
      "from plotly.graph_objs import *\n",
      "from pylab import *\n",
      "\n",
      "\n",
      "import sklearn\n",
      "from sklearn import svm\n",
      "from sklearn import datasets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import cross_val_score \n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-------------------------------------###\n",
      "###-----Generate feature vectors--------###\n",
      "###-------------------------------------###\n",
      "\n",
      "'''\n",
      "Experiments:\n",
      "E1 = LBP8-1\n",
      "E2 = LBP16-2\n",
      "E3 = LBP24-3\n",
      "E4 = LBP8-1_16-2\n",
      "E5 = LBP8-1_24-3\n",
      "E6 = LBP16-2_24-3\n",
      "E7 = LBP8-1_16-2_24-3\n",
      "\n",
      "'''\n",
      "\n",
      "y_labels = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(1,), dtype = int)\n",
      "z_names = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "E1_link = '/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/E1_2scales.csv'\n",
      "E2_link = '/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/E2_2scales.csv'\n",
      "E3_link = '/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/E3_2scales.csv'\n",
      "\n",
      "##------ Load E1, E2, E3 -------##\n",
      "\n",
      "E1 = []\n",
      "E1_LBP = open(E1_link)\n",
      "E1_LBP.readline()  # skip the header\n",
      "LBPreader = csv.reader(E1_LBP)\n",
      "for row in LBPreader:\n",
      "    E1.append(row)\n",
      "    \n",
      "E2 = []\n",
      "E2_LBP = open(E2_link)\n",
      "E2_LBP.readline()  # skip the header\n",
      "LBPreader = csv.reader(E2_LBP)\n",
      "for row in LBPreader:\n",
      "    E2.append(row)\n",
      "    \n",
      "E3 = []\n",
      "E3_LBP = open(E3_link)\n",
      "E3_LBP.readline()  # skip the header\n",
      "LBPreader = csv.reader(E3_LBP)\n",
      "for row in LBPreader:\n",
      "    E3.append(row)\n",
      "    \n",
      "##------ Create E4, E5, E6 feature vectors --------##\n",
      "def create_feat_vectores(file1, file2):\n",
      "    \n",
      "    X_LBP = []\n",
      "    f_LBP = open(file1)\n",
      "    f_LBP.readline()  # skip the header\n",
      "    LBPreader = csv.reader(f_LBP)\n",
      "    for row in LBPreader:\n",
      "        X_LBP.append(row)\n",
      "\n",
      "    X_LBP_2 = []\n",
      "    f_LBP_2 = open(file2)\n",
      "    f_LBP_2.readline()  # skip the header\n",
      "    LBPreader_2 = csv.reader(f_LBP_2)\n",
      "    for row_2 in LBPreader_2:\n",
      "        X_LBP_2.append(row_2)\n",
      "\n",
      "    \n",
      "    merged_features=[]\n",
      "    for i in range(len(X_LBP)):\n",
      "        merged_features.append(X_LBP[i]+X_LBP_2[i])\n",
      "    #print merged_features\n",
      "    print len(merged_features[0])\n",
      "    \n",
      "    return merged_features\n",
      "\n",
      "##------ Create E7 feature vector --------##\n",
      "def create_feat_vectores_3(file1, file2, file3):\n",
      "    \n",
      "    X_LBP = []\n",
      "    f_LBP = open(file1)\n",
      "    f_LBP.readline()  # skip the header\n",
      "    LBPreader = csv.reader(f_LBP)\n",
      "    for row in LBPreader:\n",
      "        X_LBP.append(row)\n",
      "\n",
      "    X_LBP_2 = []\n",
      "    f_LBP_2 = open(file2)\n",
      "    f_LBP_2.readline()  # skip the header\n",
      "    LBPreader_2 = csv.reader(f_LBP_2)\n",
      "    for row_2 in LBPreader_2:\n",
      "        X_LBP_2.append(row_2)\n",
      "        \n",
      "    X_LBP_3 = []\n",
      "    f_LBP_3 = open(file3)\n",
      "    f_LBP_3.readline()  # skip the header\n",
      "    LBPreader_3 = csv.reader(f_LBP_3)\n",
      "    for row_3 in LBPreader_3:\n",
      "        X_LBP_3.append(row_3)\n",
      "\n",
      "    \n",
      "    merged_features=[]\n",
      "    for i in range(len(X_LBP)):\n",
      "        merged_features.append(X_LBP[i]+X_LBP_2[i]+X_LBP_3[i])\n",
      "    #print merged_features\n",
      "    print len(merged_features[0])\n",
      "    \n",
      "    return merged_features\n",
      "\n",
      "E4 = create_feat_vectores(E1_link, E2_link)\n",
      "\n",
      "E5 = create_feat_vectores(E1_link, E3_link)\n",
      "\n",
      "E6 = create_feat_vectores(E2_link, E3_link)\n",
      "\n",
      "E7 = create_feat_vectores_3(E1_link, E2_link, E3_link)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "52\n",
        "68\n",
        "84\n",
        "102\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-------Split data into training + test sets--------###\n",
      "def split_data(feature_vector):\n",
      "    \n",
      "    y_labels = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(1,), dtype = int)\n",
      "    z_names = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Experiments_v2.0/lightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "    \n",
      "    X_array_features = np.array(feature_vector)\n",
      "    print X_array_features.shape\n",
      "\n",
      "    n_sample = len(X_array_features)\n",
      "    print n_sample\n",
      "\n",
      "    np.random.seed(0)\n",
      "    order = np.random.permutation(n_sample)\n",
      "    X_features = X_array_features[order]\n",
      "    y_labels = y_labels[order].astype(np.float)\n",
      "    z_names = z_names[order]\n",
      "    \n",
      "\n",
      "    X_train = X_features[:.7 * n_sample] ## select 70% of the data to train\n",
      "    y_train = y_labels[:.7 * n_sample]\n",
      "    z_train = z_names[:.7 * n_sample]\n",
      "    X_test = X_features[.7 * n_sample:]\n",
      "    y_test = y_labels[.7 * n_sample:]\n",
      "    z_test = z_names[.7 * n_sample:]\n",
      "    \n",
      "    print \"Test set:\" \n",
      "    print z_test\n",
      "\n",
      "    print \"Training set:\"\n",
      "    print z_train\n",
      "    \n",
      "    \n",
      "    return X_train, y_train, z_train, X_test, y_test, z_test\n",
      "\n",
      "X_train_E1, y_train_E1, z_train_E1, X_test_E1, y_test_E1, z_test_E1 = split_data(E1)\n",
      "X_train_E2, y_train_E2, z_train_E2, X_test_E2, y_test_E2, z_test_E2 = split_data(E2)\n",
      "X_train_E3, y_train_E3, z_train_E3, X_test_E3, y_test_E3, z_test_E3 = split_data(E3)\n",
      "X_train_E4, y_train_E4, z_train_E4, X_test_E4, y_test_E4, z_test_E4 = split_data(E4)\n",
      "X_train_E5, y_train_E5, z_train_E5, X_test_E5, y_test_E5, z_test_E5 = split_data(E5)\n",
      "X_train_E6, y_train_E6, z_train_E6, X_test_E6, y_test_E6, z_test_E6 = split_data(E6)\n",
      "X_train_E7, y_train_E7, z_train_E7, X_test_E7, y_test_E7, z_test_E7 = split_data(E7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(130, 18)\n",
        "130\n",
        "Test set:\n",
        "['18_01_m' '37_01_m' '30_01_m' '44_01_i' '44_03_i' '28_03_m' '25_01_m'\n",
        " '29_01_m' '09_05_i' '42_02_i' '26_02_i' '28_01_i' '11_01_i' '14_03_i'\n",
        " '29_02_i' '41_04_i' '17_01_i' '44_02_i' '15_02_i' '36_01_i' '22_04_i'\n",
        " '20_01_i' '06_04_m' '40_02_i' '31_05_m' '25_03_m' '31_04_m' '14_02_i'\n",
        " '39_03_i' '09_06_i' '30_02_m' '05_03_i' '36_02_i' '43_03_m' '42_03_i'\n",
        " '23_02_i' '22_03_i' '40_04_i' '17_02_i']\n",
        "Training set:\n",
        "['05_02_i' '20_02_i' '33_03_i' '36_03_i' '34_05_i' '12_01_i' '16_03_m'\n",
        " '13_02_i' '22_02_i' '11_02_i' '26_03_m' '05_01_i' '10_01_i' '36_04_i'\n",
        " '06_01_m' '17_03_i' '43_02_m' '33_01_m' '02_01_i' '34_01_i' '18_04_m'\n",
        " '34_04_i' '10_03_i' '18_03_m' '18_02_m' '15_03_m' '42_01_i' '23_04_i'\n",
        " '23_01_i' '08_03_i' '21_03_i' '41_05_m' '06_05_m' '27_03_i' '28_02_i'\n",
        " '16_04_m' '08_02_i' '33_02_m' '40_03_i' '34_03_i' '02_02_i' '16_02_m'\n",
        " '03_02_i' '31_01_m' '19_02_m' '35_02_i' '34_02_m' '39_02_i' '21_02_i'\n",
        " '37_03_i' '26_01_m' '11_03_i' '09_03_m' '37_02_m' '06_02_m' '43_01_m'\n",
        " '38_02_m' '15_04_i' '31_03_m' '21_01_m' '01_02_i' '19_04_m' '34_06_m'\n",
        " '39_01_i' '16_01_i' '02_03_i' '09_02_m' '15_01_m' '03_01_i' '19_01_m'\n",
        " '41_01_m' '35_04_i' '01_01_i' '13_03_i' '11_04_i' '19_03_m' '27_01_m'\n",
        " '14_01_i' '10_02_i' '26_04_m' '12_02_i' '31_02_m' '19_05_m' '35_03_i'\n",
        " '38_03_i' '13_01_i' '37_04_i' '08_01_i' '32_02_m' '09_04_m' '11_05_i']\n",
        "(130, 34)\n",
        "130\n",
        "Test set:\n",
        "['18_01_m' '37_01_m' '30_01_m' '44_01_i' '44_03_i' '28_03_m' '25_01_m'\n",
        " '29_01_m' '09_05_i' '42_02_i' '26_02_i' '28_01_i' '11_01_i' '14_03_i'\n",
        " '29_02_i' '41_04_i' '17_01_i' '44_02_i' '15_02_i' '36_01_i' '22_04_i'\n",
        " '20_01_i' '06_04_m' '40_02_i' '31_05_m' '25_03_m' '31_04_m' '14_02_i'\n",
        " '39_03_i' '09_06_i' '30_02_m' '05_03_i' '36_02_i' '43_03_m' '42_03_i'\n",
        " '23_02_i' '22_03_i' '40_04_i' '17_02_i']\n",
        "Training set:\n",
        "['05_02_i' '20_02_i' '33_03_i' '36_03_i' '34_05_i' '12_01_i' '16_03_m'\n",
        " '13_02_i' '22_02_i' '11_02_i' '26_03_m' '05_01_i' '10_01_i' '36_04_i'\n",
        " '06_01_m' '17_03_i' '43_02_m' '33_01_m' '02_01_i' '34_01_i' '18_04_m'\n",
        " '34_04_i' '10_03_i' '18_03_m' '18_02_m' '15_03_m' '42_01_i' '23_04_i'\n",
        " '23_01_i' '08_03_i' '21_03_i' '41_05_m' '06_05_m' '27_03_i' '28_02_i'\n",
        " '16_04_m' '08_02_i' '33_02_m' '40_03_i' '34_03_i' '02_02_i' '16_02_m'\n",
        " '03_02_i' '31_01_m' '19_02_m' '35_02_i' '34_02_m' '39_02_i' '21_02_i'\n",
        " '37_03_i' '26_01_m' '11_03_i' '09_03_m' '37_02_m' '06_02_m' '43_01_m'\n",
        " '38_02_m' '15_04_i' '31_03_m' '21_01_m' '01_02_i' '19_04_m' '34_06_m'\n",
        " '39_01_i' '16_01_i' '02_03_i' '09_02_m' '15_01_m' '03_01_i' '19_01_m'\n",
        " '41_01_m' '35_04_i' '01_01_i' '13_03_i' '11_04_i' '19_03_m' '27_01_m'\n",
        " '14_01_i' '10_02_i' '26_04_m' '12_02_i' '31_02_m' '19_05_m' '35_03_i'\n",
        " '38_03_i' '13_01_i' '37_04_i' '08_01_i' '32_02_m' '09_04_m' '11_05_i']\n",
        "(130, 50)\n",
        "130\n",
        "Test set:\n",
        "['18_01_m' '37_01_m' '30_01_m' '44_01_i' '44_03_i' '28_03_m' '25_01_m'\n",
        " '29_01_m' '09_05_i' '42_02_i' '26_02_i' '28_01_i' '11_01_i' '14_03_i'\n",
        " '29_02_i' '41_04_i' '17_01_i' '44_02_i' '15_02_i' '36_01_i' '22_04_i'\n",
        " '20_01_i' '06_04_m' '40_02_i' '31_05_m' '25_03_m' '31_04_m' '14_02_i'\n",
        " '39_03_i' '09_06_i' '30_02_m' '05_03_i' '36_02_i' '43_03_m' '42_03_i'\n",
        " '23_02_i' '22_03_i' '40_04_i' '17_02_i']\n",
        "Training set:\n",
        "['05_02_i' '20_02_i' '33_03_i' '36_03_i' '34_05_i' '12_01_i' '16_03_m'\n",
        " '13_02_i' '22_02_i' '11_02_i' '26_03_m' '05_01_i' '10_01_i' '36_04_i'\n",
        " '06_01_m' '17_03_i' '43_02_m' '33_01_m' '02_01_i' '34_01_i' '18_04_m'\n",
        " '34_04_i' '10_03_i' '18_03_m' '18_02_m' '15_03_m' '42_01_i' '23_04_i'\n",
        " '23_01_i' '08_03_i' '21_03_i' '41_05_m' '06_05_m' '27_03_i' '28_02_i'\n",
        " '16_04_m' '08_02_i' '33_02_m' '40_03_i' '34_03_i' '02_02_i' '16_02_m'\n",
        " '03_02_i' '31_01_m' '19_02_m' '35_02_i' '34_02_m' '39_02_i' '21_02_i'\n",
        " '37_03_i' '26_01_m' '11_03_i' '09_03_m' '37_02_m' '06_02_m' '43_01_m'\n",
        " '38_02_m' '15_04_i' '31_03_m' '21_01_m' '01_02_i' '19_04_m' '34_06_m'\n",
        " '39_01_i' '16_01_i' '02_03_i' '09_02_m' '15_01_m' '03_01_i' '19_01_m'\n",
        " '41_01_m' '35_04_i' '01_01_i' '13_03_i' '11_04_i' '19_03_m' '27_01_m'\n",
        " '14_01_i' '10_02_i' '26_04_m' '12_02_i' '31_02_m' '19_05_m' '35_03_i'\n",
        " '38_03_i' '13_01_i' '37_04_i' '08_01_i' '32_02_m' '09_04_m' '11_05_i']\n",
        "(130, 52)\n",
        "130\n",
        "Test set:\n",
        "['18_01_m' '37_01_m' '30_01_m' '44_01_i' '44_03_i' '28_03_m' '25_01_m'\n",
        " '29_01_m' '09_05_i' '42_02_i' '26_02_i' '28_01_i' '11_01_i' '14_03_i'\n",
        " '29_02_i' '41_04_i' '17_01_i' '44_02_i' '15_02_i' '36_01_i' '22_04_i'\n",
        " '20_01_i' '06_04_m' '40_02_i' '31_05_m' '25_03_m' '31_04_m' '14_02_i'\n",
        " '39_03_i' '09_06_i' '30_02_m' '05_03_i' '36_02_i' '43_03_m' '42_03_i'\n",
        " '23_02_i' '22_03_i' '40_04_i' '17_02_i']\n",
        "Training set:\n",
        "['05_02_i' '20_02_i' '33_03_i' '36_03_i' '34_05_i' '12_01_i' '16_03_m'\n",
        " '13_02_i' '22_02_i' '11_02_i' '26_03_m' '05_01_i' '10_01_i' '36_04_i'\n",
        " '06_01_m' '17_03_i' '43_02_m' '33_01_m' '02_01_i' '34_01_i' '18_04_m'\n",
        " '34_04_i' '10_03_i' '18_03_m' '18_02_m' '15_03_m' '42_01_i' '23_04_i'\n",
        " '23_01_i' '08_03_i' '21_03_i' '41_05_m' '06_05_m' '27_03_i' '28_02_i'\n",
        " '16_04_m' '08_02_i' '33_02_m' '40_03_i' '34_03_i' '02_02_i' '16_02_m'\n",
        " '03_02_i' '31_01_m' '19_02_m' '35_02_i' '34_02_m' '39_02_i' '21_02_i'\n",
        " '37_03_i' '26_01_m' '11_03_i' '09_03_m' '37_02_m' '06_02_m' '43_01_m'\n",
        " '38_02_m' '15_04_i' '31_03_m' '21_01_m' '01_02_i' '19_04_m' '34_06_m'\n",
        " '39_01_i' '16_01_i' '02_03_i' '09_02_m' '15_01_m' '03_01_i' '19_01_m'\n",
        " '41_01_m' '35_04_i' '01_01_i' '13_03_i' '11_04_i' '19_03_m' '27_01_m'\n",
        " '14_01_i' '10_02_i' '26_04_m' '12_02_i' '31_02_m' '19_05_m' '35_03_i'\n",
        " '38_03_i' '13_01_i' '37_04_i' '08_01_i' '32_02_m' '09_04_m' '11_05_i']\n",
        "(130, 68)\n",
        "130\n",
        "Test set:\n",
        "['18_01_m' '37_01_m' '30_01_m' '44_01_i' '44_03_i' '28_03_m' '25_01_m'\n",
        " '29_01_m' '09_05_i' '42_02_i' '26_02_i' '28_01_i' '11_01_i' '14_03_i'\n",
        " '29_02_i' '41_04_i' '17_01_i' '44_02_i' '15_02_i' '36_01_i' '22_04_i'\n",
        " '20_01_i' '06_04_m' '40_02_i' '31_05_m' '25_03_m' '31_04_m' '14_02_i'\n",
        " '39_03_i' '09_06_i' '30_02_m' '05_03_i' '36_02_i' '43_03_m' '42_03_i'\n",
        " '23_02_i' '22_03_i' '40_04_i' '17_02_i']\n",
        "Training set:\n",
        "['05_02_i' '20_02_i' '33_03_i' '36_03_i' '34_05_i' '12_01_i' '16_03_m'\n",
        " '13_02_i' '22_02_i' '11_02_i' '26_03_m' '05_01_i' '10_01_i' '36_04_i'\n",
        " '06_01_m' '17_03_i' '43_02_m' '33_01_m' '02_01_i' '34_01_i' '18_04_m'\n",
        " '34_04_i' '10_03_i' '18_03_m' '18_02_m' '15_03_m' '42_01_i' '23_04_i'\n",
        " '23_01_i' '08_03_i' '21_03_i' '41_05_m' '06_05_m' '27_03_i' '28_02_i'\n",
        " '16_04_m' '08_02_i' '33_02_m' '40_03_i' '34_03_i' '02_02_i' '16_02_m'\n",
        " '03_02_i' '31_01_m' '19_02_m' '35_02_i' '34_02_m' '39_02_i' '21_02_i'\n",
        " '37_03_i' '26_01_m' '11_03_i' '09_03_m' '37_02_m' '06_02_m' '43_01_m'\n",
        " '38_02_m' '15_04_i' '31_03_m' '21_01_m' '01_02_i' '19_04_m' '34_06_m'\n",
        " '39_01_i' '16_01_i' '02_03_i' '09_02_m' '15_01_m' '03_01_i' '19_01_m'\n",
        " '41_01_m' '35_04_i' '01_01_i' '13_03_i' '11_04_i' '19_03_m' '27_01_m'\n",
        " '14_01_i' '10_02_i' '26_04_m' '12_02_i' '31_02_m' '19_05_m' '35_03_i'\n",
        " '38_03_i' '13_01_i' '37_04_i' '08_01_i' '32_02_m' '09_04_m' '11_05_i']\n",
        "(130, 84)\n",
        "130\n",
        "Test set:\n",
        "['18_01_m' '37_01_m' '30_01_m' '44_01_i' '44_03_i' '28_03_m' '25_01_m'\n",
        " '29_01_m' '09_05_i' '42_02_i' '26_02_i' '28_01_i' '11_01_i' '14_03_i'\n",
        " '29_02_i' '41_04_i' '17_01_i' '44_02_i' '15_02_i' '36_01_i' '22_04_i'\n",
        " '20_01_i' '06_04_m' '40_02_i' '31_05_m' '25_03_m' '31_04_m' '14_02_i'\n",
        " '39_03_i' '09_06_i' '30_02_m' '05_03_i' '36_02_i' '43_03_m' '42_03_i'\n",
        " '23_02_i' '22_03_i' '40_04_i' '17_02_i']\n",
        "Training set:\n",
        "['05_02_i' '20_02_i' '33_03_i' '36_03_i' '34_05_i' '12_01_i' '16_03_m'\n",
        " '13_02_i' '22_02_i' '11_02_i' '26_03_m' '05_01_i' '10_01_i' '36_04_i'\n",
        " '06_01_m' '17_03_i' '43_02_m' '33_01_m' '02_01_i' '34_01_i' '18_04_m'\n",
        " '34_04_i' '10_03_i' '18_03_m' '18_02_m' '15_03_m' '42_01_i' '23_04_i'\n",
        " '23_01_i' '08_03_i' '21_03_i' '41_05_m' '06_05_m' '27_03_i' '28_02_i'\n",
        " '16_04_m' '08_02_i' '33_02_m' '40_03_i' '34_03_i' '02_02_i' '16_02_m'\n",
        " '03_02_i' '31_01_m' '19_02_m' '35_02_i' '34_02_m' '39_02_i' '21_02_i'\n",
        " '37_03_i' '26_01_m' '11_03_i' '09_03_m' '37_02_m' '06_02_m' '43_01_m'\n",
        " '38_02_m' '15_04_i' '31_03_m' '21_01_m' '01_02_i' '19_04_m' '34_06_m'\n",
        " '39_01_i' '16_01_i' '02_03_i' '09_02_m' '15_01_m' '03_01_i' '19_01_m'\n",
        " '41_01_m' '35_04_i' '01_01_i' '13_03_i' '11_04_i' '19_03_m' '27_01_m'\n",
        " '14_01_i' '10_02_i' '26_04_m' '12_02_i' '31_02_m' '19_05_m' '35_03_i'\n",
        " '38_03_i' '13_01_i' '37_04_i' '08_01_i' '32_02_m' '09_04_m' '11_05_i']\n",
        "(130, 102)\n",
        "130\n",
        "Test set:\n",
        "['18_01_m' '37_01_m' '30_01_m' '44_01_i' '44_03_i' '28_03_m' '25_01_m'\n",
        " '29_01_m' '09_05_i' '42_02_i' '26_02_i' '28_01_i' '11_01_i' '14_03_i'\n",
        " '29_02_i' '41_04_i' '17_01_i' '44_02_i' '15_02_i' '36_01_i' '22_04_i'\n",
        " '20_01_i' '06_04_m' '40_02_i' '31_05_m' '25_03_m' '31_04_m' '14_02_i'\n",
        " '39_03_i' '09_06_i' '30_02_m' '05_03_i' '36_02_i' '43_03_m' '42_03_i'\n",
        " '23_02_i' '22_03_i' '40_04_i' '17_02_i']\n",
        "Training set:\n",
        "['05_02_i' '20_02_i' '33_03_i' '36_03_i' '34_05_i' '12_01_i' '16_03_m'\n",
        " '13_02_i' '22_02_i' '11_02_i' '26_03_m' '05_01_i' '10_01_i' '36_04_i'\n",
        " '06_01_m' '17_03_i' '43_02_m' '33_01_m' '02_01_i' '34_01_i' '18_04_m'\n",
        " '34_04_i' '10_03_i' '18_03_m' '18_02_m' '15_03_m' '42_01_i' '23_04_i'\n",
        " '23_01_i' '08_03_i' '21_03_i' '41_05_m' '06_05_m' '27_03_i' '28_02_i'\n",
        " '16_04_m' '08_02_i' '33_02_m' '40_03_i' '34_03_i' '02_02_i' '16_02_m'\n",
        " '03_02_i' '31_01_m' '19_02_m' '35_02_i' '34_02_m' '39_02_i' '21_02_i'\n",
        " '37_03_i' '26_01_m' '11_03_i' '09_03_m' '37_02_m' '06_02_m' '43_01_m'\n",
        " '38_02_m' '15_04_i' '31_03_m' '21_01_m' '01_02_i' '19_04_m' '34_06_m'\n",
        " '39_01_i' '16_01_i' '02_03_i' '09_02_m' '15_01_m' '03_01_i' '19_01_m'\n",
        " '41_01_m' '35_04_i' '01_01_i' '13_03_i' '11_04_i' '19_03_m' '27_01_m'\n",
        " '14_01_i' '10_02_i' '26_04_m' '12_02_i' '31_02_m' '19_05_m' '35_03_i'\n",
        " '38_03_i' '13_01_i' '37_04_i' '08_01_i' '32_02_m' '09_04_m' '11_05_i']\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-------Run SVM classifier--------###\n",
      "\n",
      "C=[]\n",
      "gamma=[]\n",
      "#for i in range(21): C.append(10.0**(i-5))\n",
      "#for i in range(17): gamma.append(10**(i-14))\n",
      "\n",
      "for i in range(6): C.append(10.0**(i-1))\n",
      "for i in range(5): gamma.append(10**(i-5))\n",
      "    \n",
      "print C\n",
      "print gamma\n",
      "\n",
      "###-----------------------------------------------------------###\n",
      "#---------- Set the parameters by cross-validation -----------###\n",
      "###-----------------------------------------------------------###\n",
      "\n",
      "def SVM_parameters(X_train, y_train, X_test, y_test):\n",
      "    \n",
      "    '''\n",
      "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
      "                         'C': [1, 10, 100, 1000]},\n",
      "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "    '''\n",
      "\n",
      "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
      "                         'C': C},\n",
      "                        {'kernel': ['linear'], 'C': C}]\n",
      "\n",
      "    #scores = ['precision', 'recall']\n",
      "    scores = ['f1'] # optimize for accuracy rather than precision or recall, or for F1 if you have a situation with unbalanced classes.\n",
      "\n",
      "    dict_params = {}\n",
      "    print \"Cross-validation for multi-scale LightLines:\"\n",
      "    print(\"\")\n",
      "    for score in scores:\n",
      "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "\n",
      "        clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
      "                           scoring='%s' % score)\n",
      "        clf.fit(X_train, y_train)\n",
      "\n",
      "        print(\"Best parameters set found on development set:\")\n",
      "        print(\"\")\n",
      "        print(clf.best_params_)\n",
      "        dict_params = clf.best_params_\n",
      "        \n",
      "        print(\"Grid scores on development set:\")\n",
      "        print(\"\")\n",
      "        for params, mean_score, scores in clf.grid_scores_:\n",
      "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "                  % (mean_score, scores.std() * 2, params))\n",
      "        print(\"\")\n",
      "\n",
      "        print(\"Detailed classification report (Multi-scale LightLines):\")\n",
      "        print(\"\")\n",
      "        print(\"The model is trained on the full development set.\")\n",
      "        print(\"The scores are computed on the full evaluation set.\")\n",
      "        print()\n",
      "        y_true, y_pred = y_test, clf.predict(X_test)\n",
      "        print(classification_report(y_true, y_pred))\n",
      "        print(\"\")\n",
      "        print(\"Confusion matrix\")\n",
      "        print(confusion_matrix(y_test, y_pred))\n",
      "        print(\"\")\n",
      "        \n",
      "        \n",
      "        return dict_params\n",
      "    \n",
      "##--------------------------------------------------------##\n",
      "##-----------------------ROC curves-----------------------##\n",
      "##--------------------------------------------------------##\n",
      "\n",
      "def SVM_classifier(X_train, y_train, X_test, y_test, SVM_param):\n",
      "    print \"True binary classification:\"\n",
      "    print y_test\n",
      "    ##----------------------------------##\n",
      "    ##--------- LighLines LBP ----------##\n",
      "    ##----------------------------------##\n",
      "    if len(SVM_param)==3:\n",
      "        print \"Non-linear SVM\"\n",
      "        print \" \"\n",
      "        clf_LBP = svm.SVC(C=SVM_param['C'], kernel=SVM_param['kernel'], gamma=SVM_param['gamma'])\n",
      "        \n",
      "    else:\n",
      "        print \"Linear SVM\"\n",
      "        print \" \"\n",
      "        clf_LBP = svm.SVC(C=SVM_param['C'], kernel=SVM_param['kernel'])\n",
      "    \n",
      "    y_score = clf_LBP.fit(X_train, y_train).decision_function(X_test)\n",
      "\n",
      "    print \"Predicted LBP:\"\n",
      "    print clf_LBP.predict(X_test)\n",
      "\n",
      "    # Compute ROC curve and ROC area \n",
      "    fpr_LBP, tpr_LBP, _ = roc_curve(y_test, y_score)\n",
      "    roc_auc_LBP = auc(fpr_LBP, tpr_LBP)\n",
      "\n",
      "    # Plot of a ROC curve for a specific class\n",
      "    plt.plot(fpr_LBP, tpr_LBP, label='LBP (BIF) (AUC = %0.2f)' % roc_auc_LBP)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.05])\n",
      "    plt.xlabel('False Positive Rate')\n",
      "    plt.ylabel('True Positive Rate')\n",
      "    #plt.title('Receiver operating characteristic')\n",
      "    plt.legend(loc=\"lower right\",prop={'size':9.5})\n",
      "    \n",
      "     \n",
      "    \n",
      "SVM_param_E1 = SVM_parameters(X_train_E1, y_train_E1, X_test_E1, y_test_E1)\n",
      "SVM_classifier(X_train_E1, y_train_E1, X_test_E1, y_test_E1, SVM_param_E1)\n",
      "\n",
      "SVM_param_E2 = SVM_parameters(X_train_E2, y_train_E2, X_test_E2, y_test_E2)\n",
      "SVM_classifier(X_train_E2, y_train_E2, X_test_E2, y_test_E2, SVM_param_E2)\n",
      "\n",
      "SVM_param_E3 = SVM_parameters(X_train_E3, y_train_E3, X_test_E3, y_test_E3)\n",
      "SVM_classifier(X_train_E3, y_train_E3, X_test_E3, y_test_E3, SVM_param_E3)\n",
      "\n",
      "SVM_param_E4 = SVM_parameters(X_train_E4, y_train_E4, X_test_E4, y_test_E4)\n",
      "SVM_classifier(X_train_E4, y_train_E4, X_test_E4, y_test_E4, SVM_param_E4)\n",
      "\n",
      "SVM_param_E5 = SVM_parameters(X_train_E5, y_train_E5, X_test_E5, y_test_E5)\n",
      "SVM_classifier(X_train_E5, y_train_E5, X_test_E5, y_test_E5, SVM_param_E5)\n",
      "\n",
      "SVM_param_E6 = SVM_parameters(X_train_E6, y_train_E6, X_test_E6, y_test_E6)\n",
      "SVM_classifier(X_train_E6, y_train_E6, X_test_E6, y_test_E6, SVM_param_E6)\n",
      "\n",
      "SVM_param_E7 = SVM_parameters(X_train_E7, y_train_E7, X_test_E7, y_test_E7)\n",
      "SVM_classifier(X_train_E7, y_train_E7, X_test_E7, y_test_E7, SVM_param_E7)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
        "[1e-05, 0.0001, 0.001, 0.01, 0.1]\n",
        "Cross-validation for multi-scale LightLines:\n",
        "\n",
        "# Tuning hyper-parameters for f1\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "{'kernel': 'linear', 'C': 10000.0}\n",
        "Grid scores on development set:\n",
        "\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n",
        "0.741 (+/-0.028) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n",
        "0.741 (+/-0.028) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}\n",
        "0.869 (+/-0.056) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.0001}\n",
        "0.741 (+/-0.028) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}\n",
        "0.869 (+/-0.056) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}\n",
        "0.899 (+/-0.069) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 1.0}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 10.0}\n",
        "0.855 (+/-0.078) for {'kernel': 'linear', 'C': 100.0}\n",
        "0.888 (+/-0.056) for {'kernel': 'linear', 'C': 1000.0}\n",
        "0.908 (+/-0.063) for {'kernel': 'linear', 'C': 10000.0}\n",
        "\n",
        "Detailed classification report (Multi-scale LightLines):\n",
        "\n",
        "The model is trained on the full development set.\n",
        "The scores are computed on the full evaluation set.\n",
        "()\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.83      0.83      0.83        12\n",
        "        1.0       0.93      0.93      0.93        27\n",
        "\n",
        "avg / total       0.90      0.90      0.90        39\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[10  2]\n",
        " [ 2 25]]\n",
        "\n",
        "True binary classification:\n",
        "[ 0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Linear SVM\n",
        " \n",
        "Predicted LBP:\n",
        "[ 0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  1.\n",
        "  1.  1.  1.]\n",
        "Cross-validation for multi-scale LightLines:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "# Tuning hyper-parameters for f1\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "{'kernel': 'linear', 'C': 10000.0}\n",
        "Grid scores on development set:\n",
        "\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n",
        "0.785 (+/-0.054) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n",
        "0.785 (+/-0.054) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}\n",
        "0.858 (+/-0.149) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.0001}\n",
        "0.785 (+/-0.054) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}\n",
        "0.858 (+/-0.149) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}\n",
        "0.897 (+/-0.082) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 1.0}\n",
        "0.764 (+/-0.073) for {'kernel': 'linear', 'C': 10.0}\n",
        "0.860 (+/-0.127) for {'kernel': 'linear', 'C': 100.0}\n",
        "0.894 (+/-0.081) for {'kernel': 'linear', 'C': 1000.0}\n",
        "0.897 (+/-0.103) for {'kernel': 'linear', 'C': 10000.0}\n",
        "\n",
        "Detailed classification report (Multi-scale LightLines):\n",
        "\n",
        "The model is trained on the full development set.\n",
        "The scores are computed on the full evaluation set.\n",
        "()\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.73      0.67      0.70        12\n",
        "        1.0       0.86      0.89      0.87        27\n",
        "\n",
        "avg / total       0.82      0.82      0.82        39\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[ 8  4]\n",
        " [ 3 24]]\n",
        "\n",
        "True binary classification:\n",
        "[ 0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Linear SVM\n",
        " \n",
        "Predicted LBP:\n",
        "[ 0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  1.\n",
        "  1.  0.  1.]\n",
        "Cross-validation for multi-scale LightLines:\n",
        "\n",
        "# Tuning hyper-parameters for f1\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "{'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "Grid scores on development set:\n",
        "\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n",
        "0.781 (+/-0.064) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n",
        "0.781 (+/-0.064) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}\n",
        "0.916 (+/-0.115) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.0001}\n",
        "0.781 (+/-0.064) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}\n",
        "0.916 (+/-0.115) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}\n",
        "0.935 (+/-0.079) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 1.0}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 10.0}\n",
        "0.892 (+/-0.129) for {'kernel': 'linear', 'C': 100.0}\n",
        "0.916 (+/-0.115) for {'kernel': 'linear', 'C': 1000.0}\n",
        "0.935 (+/-0.079) for {'kernel': 'linear', 'C': 10000.0}\n",
        "\n",
        "Detailed classification report (Multi-scale LightLines):\n",
        "\n",
        "The model is trained on the full development set.\n",
        "The scores are computed on the full evaluation set.\n",
        "()\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.80      0.67      0.73        12\n",
        "        1.0       0.86      0.93      0.89        27\n",
        "\n",
        "avg / total       0.84      0.85      0.84        39\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[ 8  4]\n",
        " [ 2 25]]\n",
        "\n",
        "True binary classification:\n",
        "[ 0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Non-linear SVM\n",
        " \n",
        "Predicted LBP:\n",
        "[ 0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Cross-validation for multi-scale LightLines:\n",
        "\n",
        "# Tuning hyper-parameters for f1\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "{'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "Grid scores on development set:\n",
        "\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n",
        "0.834 (+/-0.081) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n",
        "0.834 (+/-0.081) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}\n",
        "0.897 (+/-0.103) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.0001}\n",
        "0.834 (+/-0.081) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}\n",
        "0.897 (+/-0.103) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}\n",
        "0.908 (+/-0.063) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 1.0}\n",
        "0.776 (+/-0.022) for {'kernel': 'linear', 'C': 10.0}\n",
        "0.872 (+/-0.100) for {'kernel': 'linear', 'C': 100.0}\n",
        "0.908 (+/-0.063) for {'kernel': 'linear', 'C': 1000.0}\n",
        "0.908 (+/-0.063) for {'kernel': 'linear', 'C': 10000.0}\n",
        "\n",
        "Detailed classification report (Multi-scale LightLines):\n",
        "\n",
        "The model is trained on the full development set.\n",
        "The scores are computed on the full evaluation set.\n",
        "()\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.90      0.75      0.82        12\n",
        "        1.0       0.90      0.96      0.93        27\n",
        "\n",
        "avg / total       0.90      0.90      0.89        39\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[ 9  3]\n",
        " [ 1 26]]\n",
        "\n",
        "True binary classification:\n",
        "[ 0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Non-linear SVM\n",
        " \n",
        "Predicted LBP:\n",
        "[ 0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Cross-validation for multi-scale LightLines:\n",
        "\n",
        "# Tuning hyper-parameters for f1\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "{'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "Grid scores on development set:\n",
        "\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n",
        "0.816 (+/-0.071) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n",
        "0.816 (+/-0.071) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}\n",
        "0.916 (+/-0.115) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.0001}\n",
        "0.816 (+/-0.071) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}\n",
        "0.916 (+/-0.115) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}\n",
        "0.935 (+/-0.079) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 1.0}\n",
        "0.759 (+/-0.078) for {'kernel': 'linear', 'C': 10.0}\n",
        "0.917 (+/-0.069) for {'kernel': 'linear', 'C': 100.0}\n",
        "0.935 (+/-0.079) for {'kernel': 'linear', 'C': 1000.0}\n",
        "0.894 (+/-0.116) for {'kernel': 'linear', 'C': 10000.0}\n",
        "\n",
        "Detailed classification report (Multi-scale LightLines):\n",
        "\n",
        "The model is trained on the full development set.\n",
        "The scores are computed on the full evaluation set.\n",
        "()\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.82      0.75      0.78        12\n",
        "        1.0       0.89      0.93      0.91        27\n",
        "\n",
        "avg / total       0.87      0.87      0.87        39\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[ 9  3]\n",
        " [ 2 25]]\n",
        "\n",
        "True binary classification:\n",
        "[ 0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Non-linear SVM\n",
        " \n",
        "Predicted LBP:\n",
        "[ 0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Cross-validation for multi-scale LightLines:\n",
        "\n",
        "# Tuning hyper-parameters for f1\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "{'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "Grid scores on development set:\n",
        "\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n",
        "0.837 (+/-0.100) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n",
        "0.837 (+/-0.100) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}\n",
        "0.906 (+/-0.107) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.0001}\n",
        "0.837 (+/-0.100) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}\n",
        "0.906 (+/-0.107) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}\n",
        "0.935 (+/-0.079) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 1.0}\n",
        "0.779 (+/-0.072) for {'kernel': 'linear', 'C': 10.0}\n",
        "0.906 (+/-0.107) for {'kernel': 'linear', 'C': 100.0}\n",
        "0.925 (+/-0.051) for {'kernel': 'linear', 'C': 1000.0}\n",
        "0.903 (+/-0.126) for {'kernel': 'linear', 'C': 10000.0}\n",
        "\n",
        "Detailed classification report (Multi-scale LightLines):\n",
        "\n",
        "The model is trained on the full development set.\n",
        "The scores are computed on the full evaluation set.\n",
        "()\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.80      0.67      0.73        12\n",
        "        1.0       0.86      0.93      0.89        27\n",
        "\n",
        "avg / total       0.84      0.85      0.84        39\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[ 8  4]\n",
        " [ 2 25]]\n",
        "\n",
        "True binary classification:\n",
        "[ 0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Non-linear SVM\n",
        " \n",
        "Predicted LBP:\n",
        "[ 0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Cross-validation for multi-scale LightLines:\n",
        "\n",
        "# Tuning hyper-parameters for f1\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "{'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "Grid scores on development set:\n",
        "\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n",
        "0.848 (+/-0.094) for {'kernel': 'rbf', 'C': 100.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n",
        "0.848 (+/-0.094) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}\n",
        "0.916 (+/-0.115) for {'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 1e-05}\n",
        "0.736 (+/-0.007) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.0001}\n",
        "0.848 (+/-0.094) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.001}\n",
        "0.916 (+/-0.115) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.01}\n",
        "0.916 (+/-0.042) for {'kernel': 'rbf', 'C': 10000.0, 'gamma': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 0.1}\n",
        "0.736 (+/-0.007) for {'kernel': 'linear', 'C': 1.0}\n",
        "0.785 (+/-0.054) for {'kernel': 'linear', 'C': 10.0}\n",
        "0.906 (+/-0.107) for {'kernel': 'linear', 'C': 100.0}\n",
        "0.916 (+/-0.042) for {'kernel': 'linear', 'C': 1000.0}\n",
        "0.894 (+/-0.116) for {'kernel': 'linear', 'C': 10000.0}\n",
        "\n",
        "Detailed classification report (Multi-scale LightLines):\n",
        "\n",
        "The model is trained on the full development set.\n",
        "The scores are computed on the full evaluation set.\n",
        "()\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.90      0.75      0.82        12\n",
        "        1.0       0.90      0.96      0.93        27\n",
        "\n",
        "avg / total       0.90      0.90      0.89        39\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[ 9  3]\n",
        " [ 1 26]]\n",
        "\n",
        "True binary classification:\n",
        "[ 0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n",
        "Non-linear SVM\n",
        " \n",
        "Predicted LBP:\n",
        "[ 0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
        "  1.  1.  1.]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8VOWB//HPJEBS5SoJIhCNKHIVkiAIqE1oCgIioi4o\nxf3Jpa2K1qXUll1/tKZYdGEVtbJeEAXZHy0oi0UX5VZIK2oFJOCFyk1YCWgJBAkoGS45vz+emckk\nmUxmkplzZibf9+s1L2fOnDPnyXE4zzyX8z0gIiIiIiIiIiIiIiIiIiIiIiIiIiISNS6nCxCKPn36\nWDt27HC6GCIi8WYHkBXuRklRKEjE7dixA8uy9LAsHnnkEcfLECsPHQsdCx2L4A+gT33OuXFRMYiI\niH1UMYiISBWqGOJMXl6e00WIGToWlXQsKulYNFxcDD4Dlqe/TEREQuRyuaAe5/lotxheAf4BfBJk\nnd8DezCj59lRLo+IiNQh2hXDQmBYkPdHAFcCXYCfAs9HuTwiIlKHaFcM7wLHg7w/CnjV8/xDoDVw\ncZTLJCIiQTg9+NwROOj3uhjo5FBZREQSxpo1a+q9bZMIlqO+qg+MBBxlLigo8D3Py8vTzIM4krT+\nLawmLWzZV4ubB3PylC27EklYTlcMh4AMv9edPMtq8K8YJL5YTVpg2VSRu06BrTPYXC7QjDmJUZ5Z\nSWFzuivpTeD/eJ4PAL7BzGISERGHRLti+CPwPtAVM5YwCbjH8wB4G/gC2Au8CEyJcnlERBJGWVkZ\nqampPPzwwxH93Gh3JY0LYZ0HolwGEZGEM3LkSFatWgXAvn37IvrZTo8xiIhIGLZv307fvn2pqKig\nSZMmHD58mPT09Ijuw+kxBhERCdHOnTvJzs6moqKCBx54gLNnz0a8UgC1GERE4kaPHj3Iy8tj9erV\npKSkRG0/CtGLAUlvbcJqcc6+HY4aBSdP2rc/G7VoDmU2Xsdw3NWGNhWl9u1QJAz1DdFTiyEGWC3O\n2TbPH8B18qStc/0LC13k5dm0P5uvK2hj256ksVm0aBETJkxwZN+qGEREYkhZWRlpaWmcPXuW999/\nn/nz59teBg0+i4jEiKFDh9KqVSvOnj3L0KFDHakUQC0GERHHbd++nexsczuapk2bcvToUVq2bOlY\nedRiEBFx2O7duwH4+c9/zpkzZxytFEAtBhERx40dO5axY8c6XQwftRhERKQKtRhiQPPBo3Bh33UF\nLWhBoavQtv2xETON1A5tNIFUYteUKVN4/vnnKSoqIisry+ni1EoVQww4hb3XFditsBDds0AatZKS\nEi655BLOnz9PUlISzZo1c7pIQakrSUQkinJzc2nXrh3nz59n1KhRnD9/nh49ejhdrKDUYhARiZLc\n3Fz++te/kpKSwpEjRxyfbRQqtRhERKJk7dq1PPvss5SXl8dNpQAK0YsJLpcrwccYbMxKEhGf+obo\nqcUgItJAbrebW265xeliRIwqBhGRBpg0aRKpqam8+eablJWVOV2ciNDgcwDHky6ijXXc1n0WFsZL\nr174khPz1g/SyBUXF5OZmembgrp79+64GkcIJl7ORvaOMdic6Z/oYwwiiebGG29k7dq1ANx+++0s\nX77c4RIFphv1iIjYJDU1ldTUVL755puo3mLTKWoxBKIWg4gkAM1KEhGRiFDFICISgNvt5oILLvD+\n6m5UVDGIiFQzbtw4UlNTOX36NNdcc43TxbGdBp9FRDz27dvHVVddRUVFBcnJyRw4cIBOnTo5XSzb\nqcUQQMvmZtDGrkeL5k7/xSIC0LVrVyoqKhg/fjznzp1rlJUCaFZSQJolJNI4FRcXk56enjBTUOs7\nK0kVQwCqGEQkEWi6qohIiGbOnEn//v2dLkbM0uCziDQabreb1q1bU15eTnJystPFiVlqMYhIo3Dr\nrbeSmppKeXk5gwYN4ty5c04XKWZFu8UwDHgaSAYWALOrvZ8G/D+gvacsTwCLolwmEWlkmjVrxtmz\nZ0lOTuarr74iPT3d6SLFtGi2GJKBeZjKoQcwDuhebZ0HgCIgC8gDnkTdWyISYVdeeSU/+clPOHfu\nnCqFEETzJNwf2Asc8LxeCtwC/N1vna+A3p7nLYFjgNp3IhJRO3fudLoIcSWaLYaOwEG/18WeZf5e\nAnoCh4EdwL9EsTwi0ggkyl3UnBTNiiGUCwEeBrYDHTDdSf8JtIhimUQkQT388MO4XC4uuugip4sS\n96LZlXQIyPB7nYFpNfgbBMzyPN8H7Ae6Alurf1hBQYHveV5eHnl5eZErqYjErbKyMtLT0zlz5gwA\nhYWFzhbIQYWFhRH5+6N55XMTYBeQj+kq2owZgPYfY5gLnAB+C1wMfIQZcyit9lm68llEahg5ciSr\nVq0CzA/GjRs3Olyi2BKrkRjDqZyu+jLwOHCP570XMdNVFwKXYrq1Hgf+EOBzVDGISA0ul4smTZpw\n+PBhzTYKIFYrhkhRxSAiEiZlJYmISESoYhCRmNe6dWvuuOMOp4vRaKhiEJGYNW3aNFwuFydOnGD/\n/v1OF6fRUPyEiMScsrIy0tLSOHv2LC6Xi23btpGVleV0sRoNtRhEJKa43W5atWrF2bNnGTp0KBUV\nFaoUbKZZSQFoVpKIs6677jreeecdWrZs6XRR4pqmq0aQKgYRSQSarioiceeNN97A7XY7XQypRoPP\nImI7t9tNeno6J0+eZMCAAXzwwQdOF0n8qMUgIraaMmUKqampnDx5km7duqlSiEFqMYiILUpKSrjk\nkks4f/48SUlJfPLJJ/To0cPpYkkA4bQYLohaKUQk4R04cIDz588zatQozp8/r0ohhoUyWj0IWIC5\ngU4G5oY6PwWmRLFc1WlWkohImKI5K+lpYBhw1PN6O5Ab7o5ERCQ+hNqV9GW11+ciXRARSQzz5s3D\n5XL5bqAj8SeUwecvges8z5sBD1L1LmwiIrjdbtq2bcu3337rdFGkgUJpMdwH3A90xNzHOdvzWkQE\ngEmTJpGamsq3335L7969sSyLm266yeliST2F0mK4CvhRtWXXAe9FvjgiEm9+9rOfsXDhQpKSkti9\nezdXXHGF00WSBgpltLoI00qoa1k0aVaSSAybOXMmv/nNb5wuhlQTjRC9gZipqj8H5vqt2wK4FegT\n7s4aQBWDiEiYojFdtRmmEkj2/Le551EG/FP4RRSReHfXXXc5XQSxQSg1SSZwILrFqJNaDCIOmjNn\nDtOnTwegqKhIN86JE/VtMYQy+Pwd8ATQA/ieZ5kF/CDcnYlIfHG73bRp04bTp08DsHr1alUKjUAo\n01WXAJ8DnYECTOtha/SKJCKxwJuCevr0aa655hosy+LGG290ulhig1BaDG0xWUkPAn/xPFQxiCS4\n1NRUkpOTOXDgAJ06dXK6OGKjUPqe/gYMANYCvwcOA68Ddk5W1hiDiEiYojnGMAtoDfwCeBZoiZnC\nKiIiCSjsmsSjP7A5kgWpg1oMIlFy8cUXc+TIEcrLy0lJSXG6OBJB0biOIQm4HfgVMMKz7BpMl9L8\ncHckIrFl5syZuFwujhw5QocOHVQpiE+wmmQBcDmmZZALfAV0A/4vsBIzZdUuajGIRIjb7aZVq1a4\n3W4ANmzYwODBgx0ulURDNCIxPgV6AxVAKvA1ZsD5WD3K11CqGEQi5MILL+S7775j0KBBvPeesjAT\nWTQGn89iKgWAcmA/zlQKIhJBu3btIiUlhfT0dKeLIjEqWE1yGtjr9/oKYJ/nuYVpTdhFLQYRkTBF\no8XQvd6lERHHvfHGG8ycOZOioiKniyJxpr7TVUM1DHgak9C6AJgdYJ084CmgKXDU87o6tRhEwtC2\nbVtKS0sB9F1uxKIxXbWhkoF5mMqhBzCOmq2Q1sB/AjcDvVCct0iDPPzww7hcLkpLS8nMzFSlIPUS\nypXP9dUfM0ZxwPN6KXAL8He/dX4E/DdQ7Hl9NIrlEUlorVq1oqysDIB3332X66+/3uESSbwKtWK4\nAMgAdoXx2R2Bg36vi4Frq63TBdOFtBFzM6BngP8KYx8i4nHVVVfRvHlzNm7c6HRRJM6FUjGMAv4D\nSMHctCcb+K1neTChtGGbAjlAPqby+QAT2ren+ooFBQW+53l5eeTl5YXw8SKNx5YtW5wugjissLCQ\nwsLCBn9OKIMS2zA35dmIqRTAXPzWq47tBmDu3zDM8/rfMNdF+A9AT8fc/KfA83oBsBpYXu2zNPgs\n4sftdivCQuoUzcHns8A31ZZVBFqxmq2YrqJMzP2j7wDerLbOSuB6zED1BZiupp0hfLZIo7RkyRJc\nLhepqalOF0USWChdSZ8B4z3rdsHcsOf9ELY7BzwArMGc+F/GDDzf43n/Rcyd4VYDH2Mqm5dQxSAS\nUOvWrTlx4gQACxYscLg0kshCaWJciAnOG+p5vQZ4FBOTYRd1JUmjNW3aNJ566ikAOnfuzL59++rY\nQsSIRoieVw5mnMFJqhik0XK5XLhcLrZt20ZWVpbTxZE4Es2KoRBoj7md5zLMwLPdVDFIo6WBZqmv\naFYMAJcAYz2PlsBrmO4ku6hiEBEJU7QrBq+rMVNM78Bcg2AXVQyS8Dp37kxGRgZ/+ctfnC6KJIho\nTlftgbnO4FNM9tH7mKuaRSQCXn75ZVwuF/v37+fLL790ujgiIdUkf8PkHL0OHIpucWqlFoMkHLfb\nTXp6OidPngRg2bJljB071uFSSSKxqyvJKaoYJOF4/tHSrVs3/v73v9extkj4otGV9Lrnv58EeHwc\n7o5EpKprrrmGzz77TJWCxJxgNUkH4DBwWYD1LOB/o1WoANRiEBEJUzRaDIc9/52CuaeC/2NKuDsS\naaw2bdrku0+CSDwIpSYpojJV1esTzNRVu6jFIHEpIyOD4uJiOnTowKFDTs3dkMYqGi2G+zAVQFeq\nji8cQGMMIkHNmzcPl8tFcXExaWlpqhQkrgSrSVoBbYB/x1zU5l33JHAsyuWqTi0GiQtut5u2bdvy\n7bffArBixQpuvfXWsD/noosu4vjx45EuniSwNm3aUFpaWmVZNKartgTKgLYEvhtbaYBl0aKKQeJC\nSUkJ7dq1o3fv3uzYsaPen6PvoIQr0HcmGhXDKuAmTNdRoG/o5eHurAFUMUijou+ghMuuiiGWqGKQ\nRkXfQQlXJCuGULKSrgOae57/MzAXc22DSKO1ceNGXC4Xc+fOdbooEXXgwAEGDhxYY3lmZiZZWVlk\nZ2fTr18/ioqKACgoKODSSy8lOzub7Oxs3nvvvYCfe++997Jr1y4AmjZtSnZ2NllZWdxwww2+fKgJ\nEyawZs2aGvvLycnh1KlTLFy4kEWLFtVa9nvvvZfPP//c93rFihU0bdqUo0eP+pYVFBTw4osv1vr3\nLlu2jF69etG7d28GDBjA8uXVbz8fnt27d5OTk0OXLl14+OGHA66zevVqsrKy6NmzJ4899lid244a\nNSompj9/gqlA+mCmrj4A2B3/aNnJ7v1JfOnQoYOF6V61nnzyyajsw6nv4P79+60BAwbUWJ6ZmWm5\n3W7Lsizrrbfesm677TbLsiyroKDAevHFFy3Lsqy1a9daV199dY1tS0tLrSFDhvhet2/f3vf82Wef\ntaZNm2ZZlmVNmDDBWrNmTY39eZ0+fdoaOHBgwHJX34dlWdadd95pDR8+3Jo/f75vWUFBgfXCCy8E\n/Hs3b95sde3a1Tp48KBlWZZ18uRJa9myZQH3F6rRo0dbGzZssCzLsvLz862tW7dWef/8+fNWZmam\ndejQIauiosIaPXq0tXPnzqDbLl682Jo7d26NfQX6zhB4GKBOobQYzmHuxzwa+E9MwmqL+uxMJJ7N\nmTMHl8vF4cOHadeuHZZlMW3aNKeLZRvL001x4sQJ2rRpU2P5DTfcEPC2oytXrmTIkCEBP7OsrKzK\nZwXan1dqaippaWm+lkewfZSXl7N161bmzJnD66+/XmP9QJ566ilmzJhBp06dAGjevHmDQg0rKirY\ntm0bgwcPBmDcuHG89dZbVdY5evQorVu3pkOHDrhcLnJzc1m5ciWWZdW67fDhw0P+m+qrSQjrnAQe\nBu4CbgCSsfdeDCKOW7JkCdOnTwdM0//GG290uET2u/baaykvL6ekpIQPPvigxvtvvfUWvXr1qrH8\ngw8+YMyYMb7Xx44dIzs7m7KyMs6dO+frlvJnWRbXXnstLpeLnJwcXn75ZQD69u3L+++/T9euXYPu\nY/Xq1eTn59OrVy+++uorjh8/XmsF5PX555/X2t3j7yc/+Qlbt26tsszlcvGHP/yBbt26Vfk7L7ro\nIt/rjh078re//a3Kdunp6Zw4cYJdu3Zx+eWXs2rVKrp37x5027S0NI4ePcrZs2dp2jQ6p+JQKoY7\ngB8Bk4CvgUuB/4hKaURi1Pjx49myZQtPP/20o+VwNWC6SEPHsjdv3kyzZs1YuXIl999/P+vWrcOy\nLGbNmsULL7xAWlqa7wTu7+DBg7Rv3973um3btr7K4JlnnmH69Om89NJLVbZxuVy+/fm75JJLOHjw\nYJ37WL58OXfddRcAI0eOZMWKFUyePNmXaFt9X+GoXtZQVW8Befe9aNEiJk6ciMvlIjs7myZNap6W\nq2+blpbG119/TUZGRr3KUpdQKoavgCVAP2AksBlYHJXSiMQwpysFaPjJPRJuvPFGfvSjHwHmxDZj\nxgx++tOfBt2moqKi1s+aP39+yPu2LKvWE7l3H263m7fffptNmzbhcrk4c+YMvXv3ZvLkyVx00UV8\n8803vm2OHz9O27ZtARN/vn379oCtHn8//vGP+eijj2os/8Mf/kD37t19r9u2bcuxY5XXAh86dIiO\nHWve4+z73/8+77//PgCzZ8+mRYsWAbft0KFDSMchEkIZYxgLfAiM8Tzf7HkukpCmTFFGZCDeX60f\nfvghnTt39i0L9EvYX0ZGBl9//XXA9/w/KxS1/Ur238fatWsZOXIkBw4cYP/+/Rw6dIjdu3fzzTff\nMGjQIP70pz/hdrsB+OMf/8gNN9wAwNSpU5k1axbFxcUAnDp1itdee63GvhYsWEBRUVGNh3+lAJCU\nlEROTg4bNmzAsiyWLl3KzTffXOPzSkpKANP1tHTpUsaNG+frQvPfdtSoUb5tjh07xsUXXxzycQtX\nKC2GGZjWwhHP63Tgz1Ter0EkIaxatYqRI0cCpi978uTJDpfIGUVFRb6Tr8vlorCwEDBjDADJycm+\nKZ8ul6vOX64DBw6kqKiIoUOHApVjDJZlceGFF/LKK6/U2Ka2z/zoo48YN25c0H0sX768ykkUYMSI\nEaxcuZK7776bsWPH0r9/f1/XzcyZMwHo378/v/nNbxg2bBgAKSkpzJgxI+jfVpfZs2czbtw4ysrK\nGDNmDH379gXMOMV9991HTk4Ojz76KOvXrycpKYk5c+b4xkJq2/bo0aO0bds2auMLENqFD58Avamc\n9pQE7EDpqpJALr74Yo4cMb99nnzyScdnGyXSd/D48eOMGTOG9evXN+hzTp8+TX5+vq/bJRr7iAeL\nFy+mtLSUqVOnVllu9wVuq4E1wARgIvA28E64OxKJRXPnzsXlcnHkyBE6dOjQ6Kag2qFNmzZ06dKl\nwXeqW7p0Kffcc09U9xEPli9fHvXWbKg1yW3A9Z7n7wJvRKc4tVKLQaLi+eefZ8qUKWzYsME3ZzwW\n6Dso4bIrK+kqzLTUKzH3X/glUBzuDiJEFYM0KvoOSrjs6kp6Bfgf4HZgG/D7cD9cRETiT7CKoTnw\nEvA5puVgZ8y2SET16tXLd0c1EQku2HTVVCDH89wFfM/z2oWZobQtukUTabjXXnuNO+64AzDZN+np\n6Q6XSCT2BWsxfA086Xk84ff6Cc9/RWJa27ZtfZXCc889x8mTJ0lJSXG4VLFNsdv2x26/88479OnT\nh969e3PnnXdy5swZoPY47liJ3Y4F4STdNpjd+5PI69ixowVYmZmZThelXpz6Dip2297YbcuyrJ49\ne1p79+61LMuyxo8fb73++utB47hjJXa7IYZhxij2ANODrNcPE+99W5TLI43Evn372Lx5M/v373e6\nKAnDUux2WEKJ3QZzcWVZWRkVFRV8++23tG/fvtY4boid2O36Ssbcu+GHwCFgC/AmUP0KlGRgNuZC\nuni51ajEuJSUFPr16+d0MRKKYreNSMZug4m+yM/PJyUlhcGDB3P99ddjWVaNOG7vZ8dK7HZ99Qf2\nAgc8r5cCt1CzYvgZsBzTahAJy/bt25k4cWLAk0sicv22/r+drEcadl2EYreNSMZuV1RUMGnSJN57\n7z26devGxIkTWbJkCePHjw8axx0LsdtJwHjMdNWZmPsxtMekrAbTEfD/P1gMXBtgnVuAH2AqBl3R\nIyG76qqr2LNnj9PFsFVDT+6RoNjtyMVul5SUkJSU5Ntu9OjRrFu3jvHjxweM4w7lOERCKGMMzwED\nMTfrATjlWVaXUL7BTwP/6lnXhbqSJARLlizB5XKxZ88eWrZsSXl5udNFahS8v3gVux252O309HRK\nS0s5dOgQABs3bvR1kwWK4/aKhdjta4FswNtWLyW0W3seAvz/D2ZQM1KjL6aLCSANGA6cxYxFVFFQ\nUOB7npeXR15eXghFkERz2WWX+aY3Lly4kAkTJjhboASk2G17Yrfvvfde+vbty7x58xgxYgQA3bt3\nZ86cOQC1xnEHi90uLCz0/f+Ktg8xA8TeiiHd73kwTYB9QCbQDNgOdA+y/kJqn5XUoClj4bJ7fxK6\nIUOGWJ07d3a6GFGXSN/B0tJSKz8/v8Gf89133wWdrhqJfcSDV1991XrqqadqLA/0nSGK01WfxaSp\ntgMeA94DHg9hu3PAA5jI7p3AMszA8z2eh0jY1q5dG3BKpMQuxW5HVizFbncH8j3P/0zNmUXR5qn8\n7KFky9jgdrsb7ZXK+g5KuOyK3fa6tNq63j1/Ge7OGkAVQyOyZcsW+vfvDwSe4tcY6Dso4YpkxRDK\n4PPbVFYGqZhpq7uAnuHuTKQunTt39l2t/POf/9zh0og0TqFUDNUn9eYA90ehLNKIvfzyy/z4xz8G\nTH9xaWmpwyUSabzqe93Ap9SsMKJJXUkJzjs9cdmyZQ3Kp0kU+g5KuOy6g5vXL/wevwT+iLlGQSRi\nysvLsSxLlYLDFLsdO7HbtS23I3Y7lIqhud+jGeZ2n7dEs1DS+DTW2UfxwptdVFRUxCOPPMLvfvc7\n3/IZM2ZQVFTEnDlzuO+++2pse/z4cb744gvfFb1paWkUFRWxfft27rjjDp555hnfZ3lbjv7727Zt\nG82bN2fcuHG1xmd49+EfYvf6668zZMgQ3njjjSp/R222bNnCI488wurVq/n4449Zv359rVEeoZo+\nfTpPPvkke/bsYfPmzQGjNH75y1+yYsUKPv74Y5o0acKbb5rrex966KGAy8eMGRMwkyqS6qoYkoGW\nwG89j1nAEkAZBFIvubm59OnTx+liSD14uykUux2ahsRuA7Rv3z7g8hEjRjgau90Ec5HadVTezlOk\nXjZt2uTLpGnZsqXDpZH6UOy2YUfsdrDlbdu2jXrsdrAWgzc9dTuwEvhn4HbPQzfUkZBlZGT4KoVf\n//rXnDhxwuESxTGXq/6PBtq8eTOff/45r7zyCvffbyYmWp7Y7ezsbObPnx9W7Pa+ffuYNm0a06fX\nvIeXf1eS/2eGE7s9evRooDJ22/u5gfYVjpdeeqlGgN62bduqVAqBBJpM4B+7ffjwYZo1a8aSJUtq\nXe7ljd2OlmAtBu/RSgWOYaKx/a2ISokkoXj/0aWlpfnSIqUBYmCmkmK3ox+7PWTIkFrjuOs6DpEQ\nrMWQDkwDPsFMT63+EKlTv379WLFihSqFBGApdhuwJ3Y7WBw3OBu7nQy0CPK+SJ02b67rfk4SaxS7\n7XzstsvlqjWOO1jsdqQE+z9ahLkPQyzQBW4xrri4GLfbzRVXXOF0URJCIn0Hjx8/zpgxY1i/fn2D\nPuf06dPk5+f77moWjX3Eg8WLF1NaWsrUqVOrLLf7AjeRoAYOHEhGRga9e/d2uigSgxS7HVlOx263\nxQw6xwK1GGLQxo0b+cEPzJyE1NRUvvnmG12oFiH6Dkq47GoxxEqlIDGoY8eOvkph1qxZnD59WpWC\nSIKI3nynyFKLIYa43W5SU1Np164d//jHP5wuTkLSd1DCZff9GESqSElJ0UlLJIFp8FlERKpQxSC1\n2rdvH8nJyUyZMsXpoohNFLttf+z26tWrycrKomfPnjz22GO+5XPmzOGyyy7jkksuqbJ+rMRuSyOU\nnZ3NlVde2eDYYUkMit2un7pitysqKrjvvvt4++23+fTTT9myZYtvyu0Pf/jDgKF7sRC7LY3MqlWr\ncLlcbN++nQsuuIDy8nKee+45p4slMUCx2+EJJXb76NGjtG7dmg4dOuByucjNzWXlypUA5OTk1Ggt\ngPOx29LI7Ny5k5EjRwLw5JNPMm3aNIdLJLFEsdtGJGO309PTOXHiBLt27eLyyy9n1apVNTKXqrMj\ndlsVg/j06NGDiRMnBsyukdjg8uQW1YeVl9egfW/evJlmzZqxcuVK7r//ftatW+eL3X7hhRdIS0sL\nK3Yb4JlnnmH69Om89NJLVbbxdiU1a9asyvJwYrfvuusuoDJ2e/LkyRGL3a6PQDP5XC4XixYtYuLE\nib7spuTk5Do/yxu7HShQMBJUMUgVqhRiW0NP7pGg2O3IxW4DfP/73/flP82ePZsWLerOLnUydlsS\nWChNZhF/it02Ihm7Dfgi6Y8dO8bSpUsDpsdWF+3YbVUMjczOnTtJTk7m8ccfr/NXnjRO3tjtjIwM\nLr30Ur744gvAjDFkZWUxbdq0esVue3nHGLKyspg/fz5PPPFEjW2CxW4PGjQo6D6CxW7n5OT4Yrez\nsrIoKSnhwQcfBKrGbvfq1Yvc3NwG9+HPnj2bhx56iC5dutCvX78qsdvbtm0D4NFHH6VHjx7k5uYy\na9Ys31jI448/TkZGBkePHiUjI4OFCxcCzsduxxJFYkRAr169+OyzzwDzxQynCS/2SqTvoGK3I0ux\n2xIR3imon332Gc2bN6e8vFyVgthGsduR5XTsdixRi6EB1qxZw7Bhw3juuecCXoAksSfRvoMSfZFs\nMahiCEAAurdaAAAQ3UlEQVT/KMVp+g5KuNSVJCIiUaOKIYGMGDECl8vFpk2bnC6KiMQxVQwJYPv2\n7SQnJ/POO+/QpEmTGnEBIqFSumrspKvWtq0d6ap2GAZ8DuwBpgd4fzywA/gYeA8IdEd5y052768h\nunTpYgEWYD3wwANOF0cixKnv4P79+60BAwbUWJ6ZmWm53W7Lsizrrbfesm677TbLsiyroKDAevHF\nFy3Lsqy1a9daV199dY1tS0tLrSFDhvhet2/f3vf82WeftaZNm2ZZlmVNmDDBWrNmTY39eZ0+fdoa\nOHBgwHJX34dlWdadd95pDR8+3Jo/f75vWUFBgfXCCy8E/Hs3b95sde3a1Tp48KBlWZZ18uRJa9my\nZQH3F6rRo0dbGzZssCzLsvLz862tW7dWef/8+fNWZmamdejQIauiosIaPXq0tXPnzqDbLl682Jo7\nd26NfQX6znjODWGLdoshGZiHqRx6AOOA6glRXwDfx1QIjwKaRxmi66+/nj179tCyZUvKy8t59tln\nnS6SJDBL6aphaUi6qmVZtW47fPjwuE9X7Q/sBQ54Xi8FbgH8Jxv7xzR+CHSKcpkSxqZNm1i1ahU3\n3XST00WRRkDpqoYd6arBtk1LS4v7dNWOgH8UYjFwbZD1JwNvR7VECUaVQuNS6Cqs97Z5Vl6D9q10\nVSPa6apNmtQ8LVffNt7TVcPp3xoMTAKuC/RmQUGB73leXh55MZAyaZeysjLy8/PZsmWL00URhzX0\n5B4JSleNfrpqoG07dOhQ53EoLCyksAHR7F7RrhgOAf5VWgam1VBdb+AlzFjE8UAf5F8xNCZDhw5l\n3bp1gKkgWrZs6XCJpLGyGpiu2rt3zXkl9UlXveyyy4Luw5uuunjxYt/7V1xxhS9d9f7772fq1Kmk\npKTUSFe9++67ycvLo1OnTpw6dYq33367xjjDggULQiqrf7rq4MGDWbp0KbNnz66xXklJCenp6b50\n1Q0bNvi60GrbtrZ01eo/mn/729+GVNbqol0xbAW6AJnAYeAOzAC0v0uBFcBdmPEIwdx/tn///gC+\nKXeqFMQO3nRVMC0C7y/Qa681vcDJycn1SlcdOnQoUDnGYFkWF154YcB7gARLVw0US+2/j2Dpqnff\nfbcvXdXbdTNz5kygaroqQEpKCjNmzAj6t9Vl9uzZjBs3jrKyMsaMGVMlXfW+++4jJyeHRx99lPXr\n15OUlMScOXN8YyG1bWtHuqodhgO7MCf9f/Msu8fzAFgAHAOKPI/NAT6jQVPGwmX3/qrr16+fbwrq\nr371K0fLIs5w+jsYSaWlpVZ+fn6DP+e7774LOl01EvuIB6+++qr11FNP1Vge6DtDPaer2nEHt3c8\nD38v+j3/sechHj169GDv3r2UlpY6XRSRBvNPPq3rfsbBhJqu2pB9xIPly5ezZMmSqO5DIXoBKMBM\nnKbvoIRLIXoiIhI1qhgcUlJSQpMmTaJ6Q28RkfpQxeCA3Nxc2rVrx/nz52vMnhARcZodg8/isWnT\nJt+c6ZSUFI4cOaIpqCISc9RisJH3wpNf//rXlJeXq1KQmKPYbftjt9955x369OlD7969ufPOOzlz\n5gxQexx3osRuR0KUZwbXPR84Ek6cOBGVz5XEY/d33kux2/bGbluWZfXs2dPau3evZVmWNX78eOv1\n118PGsedCLHb4kctBIlnlmK3wxJK7DbAxRdfTFlZGRUVFXz77be0b9++1jhuSIzY7UZp0qRJbNq0\nid27dztdFJGIUey2EcnYbTDRF/n5+aSkpDB48GCuv/56LMuqEcft/exEiN1uVIqLi8nMzOT8+fNx\nn2MisamwsP7Tm/PyGnbBnGK3jUjGbldUVDBp0iTee+89unXrxsSJE1myZAnjx48PGscd77HbjUb/\n/v19sdhjx45l2bJlDpdIElFDT+6RoNjtyMVul5SUkJSU5Ntu9OjRrFu3jvHjxweM4w7lOESCxhgi\noEmTJmzZsoXU1FTKy8tVKUhCshoYux1IfWK3A/1K9t+HN3b7wIED7N+/n0OHDrF7925f7Paf/vQn\n3G43QI3Y7VmzZlFcbO4McOrUKV577bUa+1qwYAFFRUU1HtUzmvxjty3LYunSpdx8881V1klPT6e0\ntJRDhw4BsHHjRl83WUlJCYAvjts/Vba22O1IUYshAq699lpuuummkPonRWKdYrftid2+99576du3\nL/PmzWPEiBEAdO/enTlz5gDUGsdtR+x2vOQxWHX9KokkBZiJ0xLpO3j8+HHGjBnD+vXrG/Q5p0+f\nJj8/39e9Eo19xIPFixdTWlrK1KlTqyyPZIhe3LQYGnKv20hxu90UFxdzxRVXOF0Ukbih2O3IUux2\nJcdbDOPGjWPp0qUkJydz7tw528oijVMitRjEHo2yxeCUffv2cdVVV1FRUUFycjIHDhxwukgiIlGl\nWUlB9O3blyuvvJKKigrGjx/PuXPnfFdFiogkKnUlBeBtkrlcLi644AJKS0tJSUmxbf8i6kqScKkr\nySb6hykijZG6kkTER7Hb9sdu1xavXdu2it2uFF7WbRjKy8ut1NRUa+jQoVWiakWc5NR3ULHb9sZu\nB4vXrm1bxW778V5hGemHN8Zi7dq1vmUtmjv914rEHkux22EJJXa7tnhty7Jq3Vax236qf0kaYufO\nnVx99dW+KahfffUV6enplStEMZxKJF4pdtuIZOx2enp6jXjt7t27B91WsdtR4Ha76dmzJ2D+B4eT\n7CjitIYkajb0x5Vit41Ixm67XK6g8dq1bavY7QhLSUnh9ttvZ8mSJZqCKnEnki3n+lLsduRit4GA\n8dqBtu3QoUNIxyES4maMIZKWL1+uSkEkTN5KSbHbkYvdhsDx2t4uNP9t/RNjox27ndAVw5w5c3xf\nABEJjTd2OyMjg0svvZQvvvgCMGMMWVlZTJs2rV6x217eMYasrCzmz5/PE088UWObYLHbgwYNCrqP\nYLHbOTk5vtjtrKwsSkpKePDBB4Gqsdu9evUiNze3wX34s2fP5qGHHqJLly7069evSuz2tm3bABOv\n3aNHD3Jzc5k1a5ZvLKS2bRW7XckKpwldVlZGeno6Z86cYdCgQbXOra6VywUx0GSXxiuRrnxW7HZk\n2RG7nXAthpEjR9KqVSvOnDlDXl5e+JWCiESUfyR2Q4Qau53oli9fzuTJk6O6j/hpMdSxwpdAV6Ac\naAX8r+e/9dKmDZSW1ndrkQZLpBaD2KNxthgsK+jj7N69lAMPPPAA31gWrepYP+hDlYKINGLx02LQ\nrydpRNRikHDFU7rqMOBpIBlYAMwOsM7vgeHAd8AEoOZlkCKNTJs2baI6T10ST11Xdocjml1JycA8\nTOXQAxgHVL8Z6wjgSqAL8FPg+bo+dOrUqb6rBRujwsJCp4sQMxL5WJSWlvquEQjlsXHjxrDWT+RH\nYz0WpRHsAo9mxdAf2AscAM4CS4Fbqq0zCnjV8/xDoDUQ8KqNsrIymjVrxjPPPAPgi7VobBL5ZBgu\nHYtKOhaVdCwaLpoVQ0fAP9Sk2LOsrnUC3juzVatWnD17lqFDh2JZFv369YtoYUVExIjmGEOoI2fV\nO1IDbue94UbLli0bVioREQkqmqNbA4ACzBgDwL8BFVQdgH4BKMR0MwF8DuQC/6j2WXuBK6JUThGR\nRLUPM44bM5pgCpUJNAO2E3jw+W3P8wHA3xARkYQ2HNiF+cX/b55l93geXvM87+8AcmwtnYiIiIiI\nxJdhmHGGPcD0Wtb5vef9HUC2TeVyQl3HYjzmGHwMvAf0tq9otgvlewHQDzgH3GZHoRwQynHIw1wk\n+ilm/C5R1XUs0oDVmC7sTzEXzyaqVzDjsp8EWSduz5vJmC6lTKApdY9JXEvijkmEciwGUpkTOIzG\nfSy8620A/ge43a7C2SiU49Aa+IzKKd9pdhXOZqEciwLgcc/zNOAYiXvHyhswJ/vaKoawz5uxFKIX\n0Qvi4lwox+ID4ITn+YfUcv1HAgjlWAD8DFgOlNhWMnuFchx+BPw35noggKN2Fc5moRyLrwDv3PaW\nmIrhnE3ls9u7wPEg74d93oyliiGiF8TFuVCOhb/JVP4iSDShfi9uoTJSJRHT50I5Dl2Ai4CNwFbg\nn+0pmu1CORYvAT2Bw5juk3+xp2gxKezzZiw1rSJ6QVycC+dvGgxMAq6LUlmcFsqxeBr4V8+6LuIn\nNTgcoRyHppiZffnABZhW5d8wfcuJJJRj8TCmiykPcw3UOqAPcDJ6xYppYZ03Y6liOAT43+U7g8om\ncW3rdPIsSzShHAswA84vYcYYgjUl41kox6IvlRdJpmGmSZ8F3ox66ewTynE4iOk+Ou15/BVzMky0\niiGUYzEImOV5vg/Yj7mX19aoly72xPV5UxfEVQrlWFyK6WcdYGvJ7BfKsfC3kMSclRTKcegGrMcM\nzl6AGYzsYV8RbRPKsZgLPOJ5fjGm4rjIpvI5IZPQBp/j8rypC+Iq1XUsFmAG1Io8j812F9BGoXwv\nvBK1YoDQjsNDmJlJnwAP2lo6e9V1LNKAtzDniU8wA/OJ6o+YsZQzmFbjJBrveVNERERERERERERE\nREREREREREREREQkHOepvC6jCHMRX21ORWB/i4AvPPv6iPpdLPgS5sIyMDEM/t6rd8mq8h6Xj4EV\nQPM61u+DmecvIhL3wsmxiUTmjf/FcEMwF/80RLRyePw/dxHwizrWnwA8G6WySCMQS+mqItVdiIl4\n+Ajza3lUgHUuwWQCFWGucL3es3wo8L5n29c8nxWIN1zsXSpvmj7N81mfUJnKeSGwChO/8AkwxrO8\nEJPV9O/A9zzl+C/Pe95WzVJMLIHXIkyFlAT8B+aq9R3AT2spo78PMKFwYOKn3we2YVonV2EiImYC\nd3jKMsZT9lcwkcvbCHwcRURi0jkqu5H+G5P508LzXhpVw+C8v6J/QWUXThKmmyUN+AvmRA3mDl+/\nDrC/hVTe1GcM5qSbg6mEvoc5oX4KZHnWm++3rTfrfyOVEQPVWwze16MxlQGYE/eXQAqmIvi/nuUp\nwBZM5k113s9JxhyXKZ7XLTzLAH6IuR8FwN2YO3Z5PYa54x+YLP5dmCwlkYBiKV1V5DRVbzvYFHMX\nrhuACqAD0A444rfOZsyv4abAnzC/vPMw4XHve9Zp5vfcnwvzi32G5zMnY7qUVnjKguf5DZjbRD6B\naRn8D7ApjL9rNfCMpxzDMZWWG9OquRr4J896LTGtlgPVtve2RDp63nvBs7w1sNizjUXlv+fq0eND\ngZsxOUpgKqEMTAUhUoMqBoll4zG//nMwA7D7gdRq67yLOXGPxPwqn4uJIF9H3cFpFuZkucJv2Q+p\nelJ1edbbg6m0bgJ+B/wZeDTEv6Mc0+V0IzAWE3rm9YCnrMF4K8zvAWswNyV6w7P/PwO3ApcR/B7P\nt5F48dsSJRpjkFjWEvNL/jzmhkSXBVjnUsztPBd4HtmYWOHrqOyLvxBzd7NAqt/A5F1M14+3K2m0\nZ9klmBP8EkzLIdAN1c9S+4+tZZjUS2/rA8xJforfNlcRvIvnNCYxdZan3C0xqZoAE/3WK6OyC867\nH/+k1bi6GbyING5l1V63xXQBfYzpLvqMyims3nXvxgwGb8N00Xgrj8FUDuruwLQoqqstovvnVA4+\ne0+oQz2f4404944r+I8x/Duwk8rBZ/+/pwkmJv1lv2UuzEn+Y8++/kzl2IW/6sflTczg8gBMd9A2\nTOvhC8/7bTxl9A4+p2K6nz7GjJkk0g2MREREREREREREREREREREREREREREREREREREJFH8f2y/\nZYyUh6gyAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10595be90>"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}