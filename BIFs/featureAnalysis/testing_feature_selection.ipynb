{
 "metadata": {
  "name": "",
  "signature": "sha256:8a786b32643593163770f629aa8f349edd904bc7b33b60889727d88972f018cd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nibabel as nib\n",
      "import numpy as np\n",
      "import scipy.ndimage\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "import matplotlib as mpl\n",
      "from scipy import stats\n",
      "from scipy import ndimage\n",
      "import glob\n",
      "import csv\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import cv2\n",
      "import cv\n",
      "from __future__ import division\n",
      "import sys\n",
      "import plotly.plotly as py\n",
      "from plotly.graph_objs import *\n",
      "from pylab import *\n",
      "from skimage.io import imread\n",
      "from skimage import data\n",
      "import sklearn\n",
      "from sklearn import svm\n",
      "from sklearn import datasets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.svm import SVC\n",
      "import fnmatch\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = '/Volumes/vph-prism5/Sara/SPIE16/Manuscript'\n",
      "\n",
      "configfiles = [os.path.join(dirpath, f)              \n",
      "    for dirpath, dirnames, files in os.walk(path)\n",
      "    for f in fnmatch.filter(files, '*_features_*.csv')]\n",
      "\n",
      "for ff in configfiles:\n",
      "    print ff\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_GLCM = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_features_4_21.csv')\n",
      "f_GLCM.readline()  # skip the header\n",
      "X_GLCM = np.loadtxt(fname = f_GLCM, delimiter = ',')\n",
      "y_GLCM = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_labels.csv', delimiter = ',', usecols=(2,), dtype = int)\n",
      "#filenames\n",
      "z_GLCM = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "\n",
      "n_sample_GLCM = len(X_GLCM)\n",
      "\n",
      "np.random.seed(0)\n",
      "order_GLCM = np.random.permutation(n_sample_GLCM)\n",
      "#order_GLCM = order_RGB\n",
      "X_GLCM = X_GLCM[order_GLCM]\n",
      "y_GLCM = y_GLCM[order_GLCM].astype(np.float)\n",
      "z_GLCM = z_GLCM[order_GLCM]\n",
      "\n",
      "\n",
      "X_train_GLCM = X_GLCM[:.7 * n_sample_GLCM] ## select 70% of the data to train\n",
      "y_train_GLCM = y_GLCM[:.7 * n_sample_GLCM]\n",
      "X_test_GLCM = X_GLCM[.7 * n_sample_GLCM:]\n",
      "y_test_GLCM = y_GLCM[.7 * n_sample_GLCM:]\n",
      "z_test_GLCM = z_GLCM[.7 * n_sample_GLCM:]\n",
      "print z_test_GLCM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['11_02_i' '14_02_i' '29_02_i' '37_01_m' '37_02_m' '06_02_m' '11_03_i'\n",
        " '33_01_m' '09_04_m' '16_04_m' '13_01_i' '20_01_i' '19_02_m' '26_02_i'\n",
        " '21_02_i' '40_02_i' '36_04_i' '08_03_i' '30_01_m' '27_01_m' '09_02_m'\n",
        " '26_03_m' '17_03_i' '11_04_i' '19_04_m' '05_03_i' '34_02_m' '40_04_i'\n",
        " '39_03_i' '28_01_i' '23_01_i']\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def seq_float_forw_select(features, max_k, criterion_func, print_steps=False):\n",
      "    \"\"\"\n",
      "    Implementation of Sequential Floating Forward Selection.\n",
      "    \n",
      "    Keyword Arguments:\n",
      "        features (list): The feature space as a list of features.\n",
      "        max_k: Termination criterion; the size of the returned feature subset.\n",
      "        criterion_func (function): Function that is used to evaluate the\n",
      "            performance of the feature subset.\n",
      "        print_steps (bool): Prints the algorithm procedure if True.\n",
      "    \n",
      "    Returns the selected feature subset, a list of features of length max_k.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # Initialization\n",
      "    feat_sub = []\n",
      "    k = 0\n",
      "\n",
      "    while True:\n",
      "\n",
      "        # Step 1: Inclusion\n",
      "        if print_steps:\n",
      "            print('\\nInclusion from features', features)\n",
      "        if len(features) > 0:\n",
      "            crit_func_max = criterion_func(feat_sub + [features[0]])\n",
      "            best_feat = features[0]\n",
      "            if len(features) > 1:\n",
      "                for x in features[1:]:\n",
      "                    crit_func_eval = criterion_func(feat_sub + [x])\n",
      "                    if crit_func_eval > crit_func_max:\n",
      "                        crit_func_max = crit_func_eval\n",
      "                        best_feat = x\n",
      "            features.remove(best_feat)\n",
      "            feat_sub.append(best_feat)\n",
      "            if print_steps:\n",
      "                print('include: {} -> feature_subset: {}'.format(best_feat, feat_sub))\n",
      "\n",
      "        # Step 2: Conditional Exclusion\n",
      "            worst_feat_val = None\n",
      "            if len(features) + len(feat_sub) > max_k:\n",
      "                crit_func_max = criterion_func(feat_sub)\n",
      "                for i in reversed(range(0,len(feat_sub))):\n",
      "                    crit_func_eval = criterion_func(feat_sub[:i] + feat_sub[i+1:])\n",
      "                    if crit_func_eval > crit_func_max:\n",
      "                        worst_feat, crit_func_max = i, crit_func_eval\n",
      "                        worst_feat_val = feat_sub[worst_feat]\n",
      "                if worst_feat_val:\n",
      "                    del feat_sub[worst_feat]\n",
      "            if print_steps:\n",
      "                print('exclude: {} -> feature subset: {}'.format(worst_feat_val, feat_sub))\n",
      "\n",
      "\n",
      "        # Termination condition\n",
      "        k = len(feat_sub)\n",
      "        if k == max_k:\n",
      "            break\n",
      "\n",
      "    return feat_sub"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from random import randint\n",
      "\n",
      "def simple_rand_crit_func(feat_sub):\n",
      "    \"\"\" \n",
      "    Returns sum of numerical values of an input list plus \n",
      "    a random integer ranging from -15 to 15. \n",
      "    \n",
      "    \"\"\"\n",
      "    return sum(feat_sub) + randint(-15,15)\n",
      "\n",
      "# Example:\n",
      "simple_rand_crit_func([1,2,4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "12"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def example_seq_float_forw_select():\n",
      "    ex_features = [6,3,1,6,8,2,3,7,9,1]\n",
      "    res_seq_flforw = seq_float_forw_select(features=ex_features, max_k=3,\\\n",
      "                                 criterion_func=simple_rand_crit_func, print_steps=True)\n",
      "    return res_seq_flforw\n",
      "\n",
      "# Run example\n",
      "res_seq_flforw = example_seq_float_forw_select()\n",
      "print('RESULT: [6, 3, 1, 6, 8, 2, 3, 7, 9, 1] ->', res_seq_flforw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('\\nInclusion from features', [6, 3, 1, 6, 8, 2, 3, 7, 9, 1])\n",
        "include: 6 -> feature_subset: [6]\n",
        "exclude: None -> feature subset: [6]\n",
        "('\\nInclusion from features', [3, 1, 6, 8, 2, 3, 7, 9, 1])\n",
        "include: 6 -> feature_subset: [6, 6]\n",
        "exclude: None -> feature subset: [6, 6]\n",
        "('\\nInclusion from features', [3, 1, 8, 2, 3, 7, 9, 1])\n",
        "include: 9 -> feature_subset: [6, 6, 9]\n",
        "exclude: 6 -> feature subset: [6, 9]\n",
        "('\\nInclusion from features', [3, 1, 8, 2, 3, 7, 1])\n",
        "include: 8 -> feature_subset: [6, 9, 8]\n",
        "exclude: 8 -> feature subset: [6, 9]\n",
        "('\\nInclusion from features', [3, 1, 2, 3, 7, 1])\n",
        "include: 7 -> feature_subset: [6, 9, 7]\n",
        "exclude: None -> feature subset: [6, 9, 7]\n",
        "('RESULT: [6, 3, 1, 6, 8, 2, 3, 7, 9, 1] ->', [6, 9, 7])\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.datasets import make_classification\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "# Build a classification task using 3 informative features\n",
      "X, y = make_classification(n_samples=1000,\n",
      "                           n_features=10,\n",
      "                           n_informative=3,\n",
      "                           n_redundant=0,\n",
      "                           n_repeated=0,\n",
      "                           n_classes=2,\n",
      "                           random_state=0,\n",
      "                           shuffle=False)\n",
      "\n",
      "# Build a forest and compute the feature importances\n",
      "forest = ExtraTreesClassifier(n_estimators=250,\n",
      "                              random_state=0)\n",
      "\n",
      "forest.fit(X, y)\n",
      "importances = forest.feature_importances_\n",
      "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
      "             axis=0)\n",
      "indices = np.argsort(importances)[::-1]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "plt.figure()\n",
      "plt.title(\"Feature importances\")\n",
      "plt.bar(range(10), importances[indices],\n",
      "       color=\"r\", yerr=std[indices], align=\"center\")\n",
      "plt.xticks(range(10), indices)\n",
      "plt.xlim([-1, 10])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Automatically created module for IPython interactive environment\n",
        "Feature ranking:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1. feature 0 (0.250398)\n",
        "2. feature 1 (0.232397)\n",
        "3. feature 2 (0.148898)\n",
        "4. feature 3 (0.055363)\n",
        "5. feature 8 (0.054010)\n",
        "6. feature 5 (0.053878)\n",
        "7. feature 6 (0.052583)\n",
        "8. feature 9 (0.051020)\n",
        "9. feature 7 (0.050963)\n",
        "10. feature 4 (0.050489)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEKCAYAAAAGvn7fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x112c2a550>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}