{
 "metadata": {
  "name": "",
  "signature": "sha256:754459ebe378ecd9a4091d9d8a3f815e5c828100dcdcc4017ce3b4c472f155cc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nibabel as nib\n",
      "import numpy as np\n",
      "import scipy.ndimage\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "import matplotlib as mpl\n",
      "from scipy import stats\n",
      "from scipy import ndimage\n",
      "import glob\n",
      "import csv\n",
      "import os\n",
      "import re\n",
      "import math\n",
      "import cv2\n",
      "import cv\n",
      "from __future__ import division\n",
      "import sys\n",
      "import plotly.plotly as py\n",
      "from plotly.graph_objs import *\n",
      "from pylab import *\n",
      "from skimage.io import imread\n",
      "from skimage import data\n",
      "\n",
      "import sklearn\n",
      "from sklearn import svm\n",
      "from sklearn import datasets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.feature_selection import RFECV\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C=[]\n",
      "gamma=[]\n",
      "\n",
      "'''\n",
      "for i in range(21): C.append(10.0**(i-5))\n",
      "for i in range(17): gamma.append(10**(i-14))\n",
      "'''\n",
      "\n",
      "for i in range(6): C.append(10.0**(i-1)) #6\n",
      "for i in range(5): gamma.append(10**(i-5)) #5\n",
      "    \n",
      "print C\n",
      "print gamma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.001, 1.0, 1000.0]\n",
        "[1e-05, 0.0001, 0.001]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-----------------------------------------------------------###\n",
      "###------------SET PARAMETERS BY CROSS-VALIDATION-------------###\n",
      "\n",
      "\n",
      "f_RGB = open('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_normalisedGRAYnifty/RGB_GLCM_features.csv','rU')\n",
      "f_RGB.readline()  # skip the header\n",
      "X_RGB = np.loadtxt(fname = f_RGB, delimiter = ',')\n",
      "y_RGB = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(1,), dtype = int)\n",
      "#filenames\n",
      "z_RGB = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "n_sample_RGB = len(X_RGB)\n",
      "\n",
      "np.random.seed(0)\n",
      "order_RGB = np.random.permutation(n_sample_RGB)\n",
      "X_RGB = X_RGB[order_RGB]\n",
      "y_RGB = y_RGB[order_RGB].astype(np.float)\n",
      "z_RGB = z_RGB[order_RGB]\n",
      "\n",
      "X_train_RGB = X_RGB[:.7 * n_sample_RGB] ## select 70% of the data to train\n",
      "y_train_RGB = y_RGB[:.7 * n_sample_RGB]\n",
      "X_test_RGB = X_RGB[.7 * n_sample_RGB:]\n",
      "y_test_RGB = y_RGB[.7 * n_sample_RGB:]\n",
      "z_test_RGB = z_RGB[.7 * n_sample_RGB:]\n",
      "print z_test_RGB\n",
      "\n",
      "###-----------------------------------------------------------###\n",
      "###-------- Set the parameters by cross-validation -----------###\n",
      "###-----------------------------------------------------------###\n",
      "\n",
      "\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
      "                     'C': [1, 10, 100, 1000]},\n",
      "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "'''\n",
      "\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
      "                     'C': C},\n",
      "                    {'kernel': ['linear'], 'C': C}]\n",
      "'''\n",
      "#scores = ['precision', 'recall']\n",
      "scores = ['accuracy', 'f1'] # optimize for accuracy rather than precision or recall, or for F1 if you have a situation with unbalanced classes.\n",
      "\n",
      "print \"RGB:\"\n",
      "\n",
      "for score in scores:\n",
      "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "    print()\n",
      "\n",
      "    clf_RGB = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
      "                       scoring='%s' % score)\n",
      "    clf_RGB.fit(X_train_RGB, y_train_RGB)\n",
      "\n",
      "    print(\"Best parameters set found on development set:\")\n",
      "    print()\n",
      "    print(clf_RGB.best_params_)\n",
      "    print()\n",
      "    print(\"Grid scores on development set:\")\n",
      "    print()\n",
      "    for params, mean_score, scores in clf_RGB.grid_scores_:\n",
      "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "              % (mean_score, scores.std() * 2, params))\n",
      "    print()\n",
      "\n",
      "    print(\"Detailed classification report (RGB):\")\n",
      "    print()\n",
      "    print(\"The model is trained on the full development set.\")\n",
      "    print(\"The scores are computed on the full evaluation set.\")\n",
      "    print()\n",
      "    y_true_RGB, y_pred_RGB = y_test_RGB, clf_RGB.predict(X_test_RGB)\n",
      "    print(classification_report(y_true_RGB, y_pred_RGB))\n",
      "    print()\n",
      "    print(\"Confusion matrix\")\n",
      "    print(confusion_matrix(y_test_RGB, y_pred_RGB))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-----------------------------------------------------------###\n",
      "###-----------------------------------------------------------###\n",
      "    \n",
      "f_GLCM = open('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_GLCM_features.csv')\n",
      "f_GLCM.readline()  # skip the header\n",
      "X_GLCM = np.loadtxt(fname = f_GLCM, delimiter = ',')\n",
      "y_GLCM = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(1,), dtype = int)\n",
      "#filenames\n",
      "z_GLCM = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "\n",
      "n_sample_GLCM = len(X_GLCM)\n",
      "\n",
      "np.random.seed(0)\n",
      "#order_GLCM = np.random.permutation(n_sample_GLCM)\n",
      "order_GLCM = order_RGB\n",
      "X_GLCM = X_GLCM[order_GLCM]\n",
      "y_GLCM = y_GLCM[order_GLCM].astype(np.float)\n",
      "z_GLCM = z_GLCM[order_GLCM]\n",
      "\n",
      "\n",
      "X_train_GLCM = X_GLCM[:.7 * n_sample_GLCM] ## select 70% of the data to train\n",
      "y_train_GLCM = y_GLCM[:.7 * n_sample_GLCM]\n",
      "X_test_GLCM = X_GLCM[.7 * n_sample_GLCM:]\n",
      "y_test_GLCM = y_GLCM[.7 * n_sample_GLCM:]\n",
      "z_test_GLCM = z_GLCM[.7 * n_sample_GLCM:]\n",
      "print z_test_GLCM\n",
      "\n",
      "\n",
      "###-----------------------------------------------------------###\n",
      "#---------- Set the parameters by cross-validation -----------###\n",
      "###-----------------------------------------------------------###\n",
      "\n",
      "'''\n",
      "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
      " #                    'C': C},\n",
      "  #                  {'kernel': ['linear'], 'C': C}]\n",
      "    \n",
      "tuned_parameters = [{'kernel': ['linear'], 'C': C}]\n",
      "'''\n",
      "\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
      "                     'C': [1, 10, 100, 1000]},\n",
      "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "\n",
      "\n",
      "#scores = ['precision', 'recall']\n",
      "scores = ['accuracy', 'f1'] # optimize for accuracy rather than precision or recall, or for F1 if you have a situation with unbalanced classes.\n",
      "    \n",
      "print \"GLCM:\"\n",
      "\n",
      "for score in scores:\n",
      "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "    print()\n",
      "\n",
      "    clf_GLCM = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
      "                       scoring='%s' % score)\n",
      "    clf_GLCM.fit(X_train_GLCM, y_train_GLCM)\n",
      "\n",
      "    print(\"Best parameters set found on development set:\")\n",
      "    print()\n",
      "    print(clf_GLCM.best_params_)\n",
      "    print()\n",
      "    print(\"Grid scores on development set:\")\n",
      "    print()\n",
      "    for params, mean_score, scores in clf_GLCM.grid_scores_:\n",
      "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "              % (mean_score, scores.std() * 2, params))\n",
      "    print()\n",
      "\n",
      "    print(\"Detailed classification report (GLCM):\")\n",
      "    print()\n",
      "    print(\"The model is trained on the full development set.\")\n",
      "    print(\"The scores are computed on the full evaluation set.\")\n",
      "    print()\n",
      "    y_true_GLCM, y_pred_GLCM = y_test_GLCM, clf_GLCM.predict(X_test_GLCM)\n",
      "    print(classification_report(y_true_GLCM, y_pred_GLCM))\n",
      "    print()\n",
      "    print(\"Confusion matrix\")\n",
      "    print(confusion_matrix(y_test_GLCM, y_pred_GLCM))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-----------------------------------------------------------###\n",
      "###------------SET PARAMETERS BY CROSS-VALIDATION-------------###\n",
      "\n",
      "\n",
      "f_RGB_LBP = open('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_normalisedGRAYnifty/RGB_LBP_features.csv','rU')\n",
      "f_RGB_LBP.readline()  # skip the header\n",
      "X_RGB_LBP = np.loadtxt(fname = f_RGB_LBP, delimiter = ',')\n",
      "y_RGB_LBP = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(1,), dtype = int)\n",
      "#filenames\n",
      "z_RGB_LBP = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "n_sample_RGB_LBP = len(X_RGB_LBP)\n",
      "\n",
      "np.random.seed(0)\n",
      "order_RGB_LBP = order_RGB\n",
      "X_RGB_LBP = X_RGB_LBP[order_RGB_LBP]\n",
      "y_RGB_LBP = y_RGB_LBP[order_RGB_LBP].astype(np.float)\n",
      "z_RGB_LBP = z_RGB_LBP[order_RGB_LBP]\n",
      "\n",
      "X_train_RGB_LBP = X_RGB_LBP[:.7 * n_sample_RGB_LBP] ## select 70% of the data to train\n",
      "y_train_RGB_LBP = y_RGB_LBP[:.7 * n_sample_RGB_LBP]\n",
      "X_test_RGB_LBP = X_RGB_LBP[.7 * n_sample_RGB_LBP:]\n",
      "y_test_RGB_LBP = y_RGB_LBP[.7 * n_sample_RGB_LBP:]\n",
      "z_test_RGB_LBP = z_RGB_LBP[.7 * n_sample_RGB_LBP:]\n",
      "print z_test_RGB_LBP\n",
      "\n",
      "###-----------------------------------------------------------###\n",
      "#---------- Set the parameters by cross-validation -----------###\n",
      "###-----------------------------------------------------------###\n",
      "\n",
      "'''\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
      "                     'C': [1, 10, 100, 1000]},\n",
      "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "'''\n",
      "\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
      "                     'C': C},\n",
      "                    {'kernel': ['linear'], 'C': C}]\n",
      "\n",
      "#scores = ['precision', 'recall']\n",
      "scores = ['accuracy', 'f1'] # optimize for accuracy rather than precision or recall, or for F1 if you have a situation with unbalanced classes.\n",
      "\n",
      "print \"RGB LBP:\"\n",
      "\n",
      "for score in scores:\n",
      "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "    print()\n",
      "\n",
      "    clf_RGB_LBP = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
      "                       scoring='%s' % score)\n",
      "    clf_RGB_LBP.fit(X_train_RGB_LBP, y_train_RGB_LBP)\n",
      "\n",
      "    print(\"Best parameters set found on development set:\")\n",
      "    print()\n",
      "    print(clf_RGB_LBP.best_params_)\n",
      "    print()\n",
      "    print(\"Grid scores on development set:\")\n",
      "    print()\n",
      "    for params, mean_score, scores in clf_RGB_LBP.grid_scores_:\n",
      "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "              % (mean_score, scores.std() * 2, params))\n",
      "    print()\n",
      "\n",
      "    print(\"Detailed classification report (RGB):\")\n",
      "    print()\n",
      "    print(\"The model is trained on the full development set.\")\n",
      "    print(\"The scores are computed on the full evaluation set.\")\n",
      "    print()\n",
      "    y_true_RGB_LBP, y_pred_RGB_LBP = y_test_RGB_LBP, clf_RGB_LBP.predict(X_test_RGB_LBP)\n",
      "    print(classification_report(y_true_RGB_LBP, y_pred_RGB_LBP))\n",
      "    print()\n",
      "    print(\"Confusion matrix\")\n",
      "    print(confusion_matrix(y_test_RGB_LBP, y_pred_RGB_LBP))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-----------------------------------------------------------###\n",
      "###-----------------------------------------------------------###\n",
      "    \n",
      "f_LBP = open('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_features.csv')\n",
      "f_LBP.readline()  # skip the header\n",
      "X_LBP = np.loadtxt(fname = f_LBP, delimiter = ',')\n",
      "y_LBP = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(1,), dtype = int)\n",
      "#filenames\n",
      "z_LBP = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/ABSTRACT/December_resultsLightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "\n",
      "n_sample_LBP = len(X_LBP)\n",
      "\n",
      "np.random.seed(0)\n",
      "#order_LBP = np.random.permutation(n_sample_LBP)\n",
      "order_LBP = order_RGB\n",
      "X_LBP = X_LBP[order_LBP]\n",
      "y_LBP = y_LBP[order_LBP].astype(np.float)\n",
      "z_LBP = z_LBP[order_LBP]\n",
      "\n",
      "X_train_LBP = X_LBP[:.7 * n_sample_LBP] ## select 70% of the data to train\n",
      "y_train_LBP = y_LBP[:.7 * n_sample_LBP]\n",
      "X_test_LBP = X_LBP[.7 * n_sample_LBP:]\n",
      "y_test_LBP = y_LBP[.7 * n_sample_LBP:]\n",
      "z_test_LBP = z_LBP[.7 * n_sample_LBP:]\n",
      "print z_test_LBP\n",
      "\n",
      "\n",
      "###-----------------------------------------------------------###\n",
      "#---------- Set the parameters by cross-validation -----------###\n",
      "###-----------------------------------------------------------###\n",
      "\n",
      "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
      " #                    'C': C},\n",
      "  #                  {'kernel': ['linear'], 'C': C}]\n",
      "    \n",
      "tuned_parameters = [{'kernel': ['linear'], 'C': C}]\n",
      "\n",
      "'''\n",
      "\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
      "                     'C': [1, 10, 100, 1000]},\n",
      "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "\n",
      "'''\n",
      "\n",
      "#scores = ['precision', 'recall']\n",
      "scores = ['accuracy', 'f1'] # optimize for accuracy rather than precision or recall, or for F1 if you have a situation with unbalanced classes.\n",
      "    \n",
      "print \"LBP:\"\n",
      "\n",
      "for score in scores:\n",
      "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "    print()\n",
      "\n",
      "    clf_LBP = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
      "                       scoring='%s' % score)\n",
      "    clf_LBP.fit(X_train_LBP, y_train_LBP)\n",
      "\n",
      "    print(\"Best parameters set found on development set:\")\n",
      "    print()\n",
      "    print(clf_LBP.best_params_)\n",
      "    print()\n",
      "    print(\"Grid scores on development set:\")\n",
      "    print()\n",
      "    for params, mean_score, scores in clf_LBP.grid_scores_:\n",
      "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "              % (mean_score, scores.std() * 2, params))\n",
      "    print()\n",
      "\n",
      "    print(\"Detailed classification report (LBP):\")\n",
      "    print()\n",
      "    print(\"The model is trained on the full development set.\")\n",
      "    print(\"The scores are computed on the full evaluation set.\")\n",
      "    print()\n",
      "    y_true_LBP, y_pred_LBP = y_test_LBP, clf_LBP.predict(X_test_LBP)\n",
      "    print(classification_report(y_true_LBP, y_pred_LBP))\n",
      "    print()\n",
      "    print(\"Confusion matrix\")\n",
      "    print(confusion_matrix(y_test_LBP, y_pred_LBP))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###-----------------------skip this one--------------------------------------------###\n",
      "###---------------Combined GLCM + LBP (LIGHTLINES)--------------------###\n",
      "\n",
      "X_GLCM = []\n",
      "f_GLCM = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_features_4_21.csv')\n",
      "f_GLCM.readline()  # skip the header\n",
      "GLCMreader = csv.reader(f_GLCM)\n",
      "for row in GLCMreader:\n",
      "    X_GLCM.append(row)\n",
      "    \n",
      "y_labels = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_labels.csv', delimiter = ',', usecols=(2,), dtype = int)\n",
      "#filenames\n",
      "z_names = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "\n",
      "X_LBP = []\n",
      "f_LBP = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_LBP_features_r2.csv')\n",
      "f_LBP.readline()  # skip the header\n",
      "LBPreader = csv.reader(f_LBP)\n",
      "for row in LBPreader:\n",
      "    X_LBP.append(row)\n",
      "    \n",
      "merged_features=[]\n",
      "for i in range(len(X_GLCM)):\n",
      "    merged_features.append(X_GLCM[i]+X_LBP[i])\n",
      "    \n",
      "#print len(merged_features)\n",
      "#print merged_features[0:2]\n",
      "\n",
      "X_array_features = np.array(merged_features)\n",
      "print X_array_features.shape\n",
      "\n",
      "n_sample = len(X_array_features)\n",
      "\n",
      "np.random.seed(0)\n",
      "#order = np.random.permutation(n_sample)\n",
      "order = order_RGB\n",
      "X_features = X_array_features[order]\n",
      "y_labels = y_labels[order].astype(np.float)\n",
      "z_names = z_names[order]\n",
      "\n",
      "X_train = X_features[:.7 * n_sample] ## select 70% of the data to train\n",
      "y_train = y_labels[:.7 * n_sample]\n",
      "X_test = X_features[.7 * n_sample:]\n",
      "y_test = y_labels[.7 * n_sample:]\n",
      "z_test = z_names[.7 * n_sample:]\n",
      "print z_test\n",
      "\n",
      "###-----------------------------------------------------------###\n",
      "#---------- Set the parameters by cross-validation -----------###\n",
      "###-----------------------------------------------------------###\n",
      "\n",
      "'''\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
      "                     'C': [1, 10, 100, 1000]},\n",
      "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "'''\n",
      "\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
      "                     'C': C},\n",
      "                    {'kernel': ['linear'], 'C': C}]\n",
      "\n",
      "#scores = ['precision', 'recall']\n",
      "scores = ['accuracy', 'f1'] # optimize for accuracy rather than precision or recall, or for F1 if you have a situation with unbalanced classes.\n",
      "\n",
      "print \"RGB:\"\n",
      "\n",
      "for score in scores:\n",
      "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "    print()\n",
      "\n",
      "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
      "                       scoring='%s' % score)\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    print(\"Best parameters set found on development set:\")\n",
      "    print()\n",
      "    print(clf.best_params_)\n",
      "    print()\n",
      "    print(\"Grid scores on development set:\")\n",
      "    print()\n",
      "    for params, mean_score, scores in clf.grid_scores_:\n",
      "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "              % (mean_score, scores.std() * 2, params))\n",
      "    print()\n",
      "\n",
      "    print(\"Detailed classification report (RGB):\")\n",
      "    print()\n",
      "    print(\"The model is trained on the full development set.\")\n",
      "    print(\"The scores are computed on the full evaluation set.\")\n",
      "    print()\n",
      "    y_true, y_pred = y_test, clf.predict(X_test)\n",
      "    print(classification_report(y_true, y_pred))\n",
      "    print()\n",
      "    print(\"Confusion matrix\")\n",
      "    print(confusion_matrix(y_test, y_pred))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###------------------------SKIP THIS ONE-----------------------------------###\n",
      "###----------------Combined GLCM + LBP (RGB)------------------###\n",
      "\n",
      "X_GLCM = []\n",
      "f_GLCM = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/RGB/RGB_GLCM_features_4_21.csv')\n",
      "f_GLCM.readline()  # skip the header\n",
      "GLCMreader = csv.reader(f_GLCM)\n",
      "for row in GLCMreader:\n",
      "    X_GLCM.append(row)\n",
      "    \n",
      "y_labels = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_labels.csv', delimiter = ',', usecols=(2,), dtype = int)\n",
      "#filenames\n",
      "z_names = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "\n",
      "X_LBP = []\n",
      "f_LBP = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/RGB/RGB_LBP_features_r2.csv')\n",
      "f_LBP.readline()  # skip the header\n",
      "LBPreader = csv.reader(f_LBP)\n",
      "for row in LBPreader:\n",
      "    X_LBP.append(row)\n",
      "    \n",
      "merged_features=[]\n",
      "for i in range(len(X_GLCM)):\n",
      "    merged_features.append(X_GLCM[i]+X_LBP[i])\n",
      "    \n",
      "#print len(merged_features)\n",
      "#print merged_features[0:2]\n",
      "\n",
      "X_array_features = np.array(merged_features)\n",
      "print X_array_features.shape\n",
      "\n",
      "n_sample = len(X_array_features)\n",
      "\n",
      "np.random.seed(0)\n",
      "#order = np.random.permutation(n_sample)\n",
      "order = order_RGB\n",
      "X_features = X_array_features[order]\n",
      "y_labels = y_labels[order].astype(np.float)\n",
      "z_names = z_names[order]\n",
      "\n",
      "X_train_1 = X_features[:.7 * n_sample] ## select 70% of the data to train\n",
      "y_train_1 = y_labels[:.7 * n_sample]\n",
      "X_test_1 = X_features[.7 * n_sample:]\n",
      "y_test_1 = y_labels[.7 * n_sample:]\n",
      "z_test_1 = z_names[.7 * n_sample:]\n",
      "print z_test_1\n",
      "\n",
      "###-----------------------------------------------------------###\n",
      "#---------- Set the parameters by cross-validation -----------###\n",
      "###-----------------------------------------------------------###\n",
      "\n",
      "'''\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5],\n",
      "                     'C': [1, 10, 100, 1000]},\n",
      "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
      "'''\n",
      "\n",
      "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma,\n",
      "                     'C': C},\n",
      "                    {'kernel': ['linear'], 'C': C}]\n",
      "\n",
      "#scores = ['precision', 'recall']\n",
      "scores = ['accuracy', 'f1'] # optimize for accuracy rather than precision or recall, or for F1 if you have a situation with unbalanced classes.\n",
      "\n",
      "print \"RGB:\"\n",
      "\n",
      "for score in scores:\n",
      "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "    print()\n",
      "\n",
      "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
      "                       scoring='%s' % score)\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    print(\"Best parameters set found on development set:\")\n",
      "    print()\n",
      "    print(clf.best_params_)\n",
      "    print()\n",
      "    print(\"Grid scores on development set:\")\n",
      "    print()\n",
      "    for params, mean_score, scores in clf.grid_scores_:\n",
      "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "              % (mean_score, scores.std() * 2, params))\n",
      "    print()\n",
      "\n",
      "    print(\"Detailed classification report (RGB):\")\n",
      "    print()\n",
      "    print(\"The model is trained on the full development set.\")\n",
      "    print(\"The scores are computed on the full evaluation set.\")\n",
      "    print()\n",
      "    y_true, y_pred = y_test, clf.predict(X_test)\n",
      "    print(classification_report(y_true, y_pred))\n",
      "    print()\n",
      "    print(\"Confusion matrix\")\n",
      "    print(confusion_matrix(y_test, y_pred))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##--------------------------------------------------------##\n",
      "##-----------------------ROC curves-----------------------##\n",
      "##--------------------------------------------------------##\n",
      "\n",
      "print \"True binary classification:\"\n",
      "print y_test_RGB\n",
      "\n",
      "##------------------------##\n",
      "##------RGB GLCM----------##\n",
      "##------------------------##\n",
      "#clf_RGB = svm.SVC(C=1, kernel='rbf', gamma=1e-05)\n",
      "clf_RGB = svm.SVC(C=0.1, kernel='linear')\n",
      "y_score_RGB = clf_RGB.fit(X_train_RGB, y_train_RGB).decision_function(X_test_RGB)\n",
      "\n",
      "print \"Predicted RGB GLCM:\"\n",
      "print clf_RGB.predict(X_test_RGB)\n",
      "\n",
      "\n",
      "# Compute ROC curve and ROC area for each class\n",
      "\n",
      "fpr_RGB, tpr_RGB, _ = roc_curve(y_test_RGB, y_score_RGB)\n",
      "roc_auc_RGB = auc(fpr_RGB, tpr_RGB)\n",
      "\n",
      "# Plot of a ROC curve \n",
      "plt.figure()\n",
      "plt.plot(fpr_RGB, tpr_RGB, label='GLCM(RGB H&E) (AUC = %0.2f)' % roc_auc_RGB)\n",
      "\n",
      "##------------------------##\n",
      "##------RGB LBP-----------##\n",
      "##------------------------##\n",
      "clf_RGB_LBP = svm.SVC(C=10000, kernel='rbf', gamma=0.1)\n",
      "#clf_RGB_LBP = svm.SVC(C=0.1, kernel='linear')\n",
      "y_score_RGB_LBP = clf_RGB_LBP.fit(X_train_RGB_LBP, y_train_RGB_LBP).decision_function(X_test_RGB_LBP)\n",
      "\n",
      "print \"Predicted RGB BIFs:\"\n",
      "print clf_RGB_LBP.predict(X_test_RGB_LBP)\n",
      "\n",
      "\n",
      "# Compute ROC curve and ROC area for each class\n",
      "fpr_RGB_LBP, tpr_RGB_LBP, _ = roc_curve(y_test_RGB_LBP, y_score_RGB_LBP)\n",
      "roc_auc_RGB_LBP = auc(fpr_RGB_LBP, tpr_RGB_LBP)\n",
      "\n",
      "# Plot of a ROC curve \n",
      "plt.plot(fpr_RGB_LBP, tpr_RGB_LBP, label='LBP(RGB H&E) (AUC = %0.2f)' % roc_auc_RGB_LBP)\n",
      "\n",
      "\n",
      "\n",
      "##------------------------------##\n",
      "##------LighLines GLCM----------##\n",
      "##------------------------------##\n",
      "#clf_GLCM = svm.SVC(C=0.1, kernel='rbf', gamma=1e-05)\n",
      "clf_GLCM = svm.SVC(C=1000, kernel='linear')\n",
      "y_score_GLCM = clf_GLCM.fit(X_train_GLCM, y_train_GLCM).decision_function(X_test_GLCM)\n",
      "\n",
      "print \"Predicted GLCM:\"\n",
      "print clf_GLCM.predict(X_test_GLCM)\n",
      "\n",
      "fpr_GLCM, tpr_GLCM, _ = roc_curve(y_test_GLCM, y_score_GLCM)\n",
      "roc_auc_GLCM = auc(fpr_GLCM, tpr_GLCM)\n",
      "\n",
      "# Plot of a ROC curve \n",
      "plt.plot(fpr_GLCM, tpr_GLCM, label='GLCM (BIF)(AUC = %0.2f)' % roc_auc_GLCM)\n",
      "\n",
      "\n",
      "'''\n",
      "# The \"accuracy\" scoring is proportional to the number of correct\n",
      "# classifications\n",
      "rfecv_GLCM = RFECV(estimator=clf_GLCM, step=1, cv=StratifiedKFold(y_test_GLCM, 2),\n",
      "              scoring='accuracy')\n",
      "rfecv_GLCM.fit(X_test_GLCM, y_test_GLCM)\n",
      "\n",
      "print(\"Optimal number of features : %d\" % rfecv_GLCM.n_features_)\n",
      "print ( rfecv_GLCM.ranking_ )\n",
      "\n",
      "# Plot number of features VS. cross-validation scores\n",
      "plt.figure()\n",
      "plt.xlabel(\"Number of features selected\")\n",
      "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
      "plt.plot(range(1, len(rfecv_GLCM.grid_scores_) + 1), rfecv_GLCM.grid_scores_)\n",
      "plt.show()\n",
      "'''\n",
      "\n",
      "##----------------------------------##\n",
      "##--------- LighLines LBP ----------##\n",
      "##----------------------------------##\n",
      "clf_LBP = svm.SVC(C=10000, kernel='linear')\n",
      "y_score_LBP = clf_LBP.fit(X_train_LBP, y_train_LBP).decision_function(X_test_LBP)\n",
      "\n",
      "print \"Predicted LBP:\"\n",
      "print clf_LBP.predict(X_test_LBP)\n",
      "\n",
      "# Compute ROC curve and ROC area \n",
      "\n",
      "fpr_LBP, tpr_LBP, _ = roc_curve(y_test_LBP, y_score_LBP)\n",
      "roc_auc_LBP = auc(fpr_LBP, tpr_LBP)\n",
      "\n",
      "\n",
      "# Plot of a ROC curve for a specific class\n",
      "plt.plot(fpr_LBP, tpr_LBP, label='LBP (BIF) (AUC = %0.2f)' % roc_auc_LBP)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "#plt.title('Receiver operating characteristic')\n",
      "plt.legend(loc=\"lower right\",prop={'size':9.5})\n",
      "plt.show()\n",
      "\n",
      "'''\n",
      "##--------------------------------------------------##\n",
      "##--------- LighLines Combined GLCM + LBP ----------##\n",
      "##--------------------------------------------------##\n",
      "\n",
      "clf_combined_L = svm.SVC(C=10, kernel='linear')\n",
      "y_score_combined_L = clf_combined_L.fit(X_train, y_train).decision_function(X_test)\n",
      "\n",
      "print \"Predicted Combined (BIFS):\"\n",
      "print clf_combined_L.predict(X_test)\n",
      "\n",
      "# Compute ROC curve and ROC area \n",
      "\n",
      "fpr_combined_L, tpr_combined_L, _ = roc_curve(y_test, y_score_combined_L)\n",
      "roc_auc_combined_L = auc(fpr_combined_L, tpr_combined_L)\n",
      "\n",
      "\n",
      "# Plot of a ROC curve for a specific class\n",
      "plt.plot(fpr_combined_L, tpr_combined_L, label='GLCM + LBP (BIF) (AUC = %0.2f)' % roc_auc_combined_L)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "#plt.title('Receiver operating characteristic')\n",
      "plt.legend(loc=\"lower right\",prop={'size':9.5})\n",
      "plt.show()\n",
      "\n",
      "##--------------------------------------------##\n",
      "##--------- RGB Combined GLCM + LBP ----------##\n",
      "##--------------------------------------------##\n",
      "\n",
      "clf_combined_R = svm.SVC(C=10, kernel='linear')\n",
      "y_score_combined_R = clf_combined_R.fit(X_train_1, y_train_1).decision_function(X_test_1)\n",
      "\n",
      "print \"Predicted Combined (RGB):\"\n",
      "print clf_combined_R.predict(X_test_1)\n",
      "\n",
      "# Compute ROC curve and ROC area \n",
      "\n",
      "fpr_combined_R, tpr_combined_R, _ = roc_curve(y_test_1, y_score_combined_R)\n",
      "roc_auc_combined_R = auc(fpr_combined_R, tpr_combined_R)\n",
      "\n",
      "\n",
      "# Plot of a ROC curve for a specific class\n",
      "plt.plot(fpr_combined_R, tpr_combined_R, label='GLCM + LBP (RGB) (AUC = %0.2f)' % roc_auc_combined_R)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "#plt.title('Receiver operating characteristic')\n",
      "plt.legend(loc=\"lower right\",prop={'size':9.5})\n",
      "plt.show()\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#######################\n",
      "#######################\n",
      "#######################\n",
      "#######################\n",
      "\n",
      "'''\n",
      "###########################################\n",
      "########### FEATURE SELECTION #############\n",
      "###########################################\n",
      "\n",
      "from sklearn.datasets import make_classification\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "# Build a forest and compute the feature importances\n",
      "forest = ExtraTreesClassifier(n_estimators=250,\n",
      "                              random_state=0)\n",
      "\n",
      "forest.fit(X_test_RGB, y_test_RGB)\n",
      "importances = forest.feature_importances_\n",
      "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
      "             axis=0)\n",
      "indices = np.argsort(importances)[::-1]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(28):\n",
      "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "plt.figure()\n",
      "plt.title(\"Feature importances\")\n",
      "plt.bar(range(28), importances[indices],\n",
      "       color=\"r\", yerr=std[indices], align=\"center\")\n",
      "plt.xticks(range(28), indices)\n",
      "plt.xlim([-1, 28])\n",
      "plt.show()\n",
      "\n",
      "# The \"accuracy\" scoring is proportional to the number of correct\n",
      "# classifications\n",
      "rfecv = RFECV(estimator=clf_RGB, step=1, cv=StratifiedKFold(y_test_RGB, 2),\n",
      "              scoring='accuracy')\n",
      "y_score_RGB_rfe = rfecv.fit(X_test_RGB, y_test_RGB)\n",
      "\n",
      "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
      "print ( rfecv.ranking_ )\n",
      "\n",
      "# Plot number of features VS. cross-validation scores\n",
      "import matplotlib.pyplot as plt\n",
      "plt.figure()\n",
      "plt.xlabel(\"Number of features selected\")\n",
      "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
      "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
      "plt.show()\n",
      "\n",
      "fpr_rfe, tpr_rfe, _ = roc_curve(y_test_RGB, y_score_RGB_rfe)\n",
      "roc_auc_rfe = auc(fpr_rfe, tpr_rfe)\n",
      "# Plot of a ROC curve for a specific class\n",
      "plt.plot(fpr_rfe, tpr_rfe, label='RFE (RGB HE) (AUC = %0.2f)' % roc_auc_rfe)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "#plt.title('Receiver operating characteristic')\n",
      "plt.legend(loc=\"lower right\",prop={'size':9.5})\n",
      "plt.show()\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##------------------------##\n",
      "##------RGB GLCM----------##\n",
      "##------------------------##\n",
      "\n",
      "f_RGB = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/RGB/RGB_GLCM_features_4_7.csv','rU')\n",
      "f_RGB.readline()  # skip the header\n",
      "X_RGB = np.loadtxt(fname = f_RGB, delimiter = ',')\n",
      "\n",
      "#t_RGB = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/RGB/samples_labels_GLCM_RGB.csv')\n",
      "y_RGB = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/RGB/RGB_GLCM_labels.csv', delimiter = ',', usecols=(2,), dtype = int)\n",
      "\n",
      "\n",
      "z_RGB = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/RGB/RGB_GLCM_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "#clf_RGB = svm.SVC(C=1, kernel='rbf', gamma=1e-05)\n",
      "clf_RGB = svm.SVC(C=1000, kernel='linear')\n",
      "y_score_RGB = clf_RGB.fit(X_train_RGB, y_train_RGB).decision_function(X_test_RGB)\n",
      "\n",
      "print \"Predicted RGB:\"\n",
      "print clf_RGB.predict(X_test_RGB)\n",
      "\n",
      "# Compute ROC curve and ROC area for each class\n",
      "\n",
      "fpr_RGB, tpr_RGB, _ = roc_curve(y_test_RGB, y_score_RGB)\n",
      "roc_auc_RGB = auc(fpr_RGB, tpr_RGB)\n",
      "\n",
      "\n",
      "# Plot of a ROC curve \n",
      "plt.figure()\n",
      "plt.plot(fpr_RGB, tpr_RGB, label='GLCM(RGB H&E) (AUC = %0.2f)' % roc_auc_RGB)\n",
      "\n",
      "\n",
      "##------------------------------##\n",
      "##------LighLines GLCM----------##\n",
      "##------------------------------##\n",
      "\n",
      "f_GLCM = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_LBP_features_r2.csv')\n",
      "f_GLCM.readline()  # skip the header\n",
      "X_GLCM = np.loadtxt(fname = f_GLCM, delimiter = ',')\n",
      "\n",
      "#t_GLCM = open('/Volumes/vph-prism5/Sara/SPIE16/new_resultsLightLines/samples_labels_GLCM_lightlines.csv')\n",
      "y_GLCM = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_labels.csv', delimiter = ',', usecols=(2,), dtype = int)\n",
      "z_GLCM = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_GLCM_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "clf_GLCM = svm.SVC(C=1000, kernel='rbf', gamma=1e-05)\n",
      "#clf_GLCM = svm.SVC(C=10, kernel='linear')\n",
      "y_score_GLCM = clf_GLCM.fit(X_train_GLCM, y_train_GLCM).decision_function(X_test_GLCM)\n",
      "\n",
      "print \"Predicted GLCM:\"\n",
      "print clf_GLCM.predict(X_test_GLCM)\n",
      "\n",
      "fpr_GLCM, tpr_GLCM, _ = roc_curve(y_test_GLCM, y_score_GLCM)\n",
      "roc_auc_GLCM = auc(fpr_GLCM, tpr_GLCM)\n",
      "\n",
      "\n",
      "# Plot of a ROC curve \n",
      "\n",
      "plt.plot(fpr_GLCM, tpr_GLCM, label='GLCM (BIF (AUC = %0.2f)' % roc_auc_GLCM)\n",
      "\n",
      "##------------------------##\n",
      "##--------- LBP ----------##\n",
      "##------------------------##\n",
      "\n",
      "f_LBP = open('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_LBP_features_r2.csv')\n",
      "f_LBP.readline()  # skip the header\n",
      "X_LBP = np.loadtxt(fname = f_LBP, delimiter = ',')\n",
      "#t_LBP = open('/Volumes/vph-prism5/Sara/SPIE16/new_resultsLightLines/LightLines_LBP_labels.csv')\n",
      "y_LBP = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(2,), dtype = int)\n",
      "z_LBP = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/Manuscript/LightLines/LightLines_LBP_labels.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "\n",
      "clf_LBP = svm.SVC(C=1000, kernel='linear')\n",
      "y_score_LBP = clf_LBP.fit(X_train_LBP, y_train_LBP).decision_function(X_test_LBP)\n",
      "\n",
      "print \"Predicted LBP:\"\n",
      "print clf_LBP.predict(X_test_LBP)\n",
      "\n",
      "# Compute ROC curve and ROC area \n",
      "\n",
      "fpr_LBP, tpr_LBP, _ = roc_curve(y_test_LBP, y_score_LBP)\n",
      "roc_auc_LBP = auc(fpr_LBP, tpr_LBP)\n",
      "\n",
      "# Plot of a ROC curve for a specific class\n",
      "plt.plot(fpr_LBP, tpr_LBP, label='LBP (BIF) (AUC = %0.2f)' % roc_auc_LBP)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "#plt.title('Receiver operating characteristic')\n",
      "plt.legend(loc=\"lower right\",prop={'size':9.5})\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#######################\n",
      "#######################\n",
      "#######################\n",
      "#######################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_GLCM = open('/Volumes/vph-prism5/Sara/SPIE16/resultsLightLines/GCLMfeatures_lightlines.csv')\n",
      "f_GLCM.readline()  # skip the header\n",
      "X_GLCM = np.loadtxt(fname = f_GLCM, delimiter = ',')\n",
      "\n",
      "t_GLCM = open('/Volumes/vph-prism5/Sara/SPIE16/resultsLightLines/samples_labels_GLCM_lightlines.csv')\n",
      "y_GLCM = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/resultsLightLines/samples_labels_GLCM_lightlines.csv', delimiter = ',', usecols=(2,), dtype = int)\n",
      "\n",
      "\n",
      "z_GLCM = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/resultsLightLines/samples_labels_GLCM_lightlines.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "\n",
      "n_sample_GLCM = len(X_GLCM)\n",
      "\n",
      "np.random.seed(0)\n",
      "order_GLCM = np.random.permutation(n_sample_GLCM)\n",
      "X_GLCM = X_GLCM[order_GLCM]\n",
      "y_GLCM = y_GLCM[order_GLCM].astype(np.float)\n",
      "z_GLCM = z_GLCM[order_GLCM]\n",
      "\n",
      "X_train_GLCM = X_GLCM[:.7 * n_sample_GLCM] ## select 90% of the data to train\n",
      "y_train_GLCM = y_GLCM[:.7 * n_sample_GLCM]\n",
      "X_test_GLCM = X_GLCM[.7 * n_sample_GLCM:]\n",
      "y_test_GLCM = y_GLCM[.7 * n_sample_GLCM:]\n",
      "z_test_GLCM = z_GLCM[.7 * n_sample_GLCM:]\n",
      "\n",
      "clf_GLCM = svm.SVC(C=1, kernel='linear')\n",
      "y_score_GLCM = clf_GLCM.fit(X_train_GLCM, y_train_GLCM).decision_function(X_test_GLCM)\n",
      "\n",
      "fpr_GLCM, tpr_GLCM, _ = roc_curve(y_test_GLCM, y_score_GLCM)\n",
      "roc_auc_GLCM = auc(fpr_GLCM, tpr_GLCM)\n",
      "\n",
      "\n",
      "# Plot of a ROC curve \n",
      "\n",
      "plt.plot(fpr_GLCM, tpr_GLCM, label='GLCM (area = %0.2f)' % roc_auc_GLCM)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver operating characteristic example')\n",
      "plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_LBP = open('/Volumes/vph-prism5/Sara/SPIE16/resultsLightLines/LBPfeatures.csv')\n",
      "f_LBP.readline()  # skip the header\n",
      "X_LBP = np.loadtxt(fname = f_LBP, delimiter = ',')\n",
      "t_LBP = open('/Volumes/vph-prism5/Sara/SPIE16/resultsLightLines/samples_labels_LBP.csv')\n",
      "y_LBP = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/resultsLightLines/samples_labels_LBP.csv', delimiter = ',', usecols=(2,), dtype = int)\n",
      "\n",
      "\n",
      "z_LBP = np.loadtxt('/Volumes/vph-prism5/Sara/SPIE16/resultsLightLines/samples_labels_LBP.csv', delimiter = ',', usecols=(0,), dtype = str)\n",
      "\n",
      "\n",
      "n_sample_LBP = len(X_LBP)\n",
      "\n",
      "np.random.seed(0)\n",
      "order_LBP = np.random.permutation(n_sample_LBP)\n",
      "X_LBP = X_LBP[order_LBP]\n",
      "y_LBP = y_LBP[order_LBP].astype(np.float)\n",
      "z_LBP = z_LBP[order_LBP]\n",
      "\n",
      "X_train_LBP = X_LBP[:.7 * n_sample_LBP] ## select 90% of the data to train\n",
      "y_train_LBP = y_LBP[:.7 * n_sample_LBP]\n",
      "X_test_LBP = X_LBP[.7 * n_sample_LBP:]\n",
      "y_test_LBP = y_LBP[.7 * n_sample_LBP:]\n",
      "z_test_LBP = z_LBP[.7 * n_sample_LBP:]\n",
      "\n",
      "clf_LBP = svm.SVC(C=1000, kernel='linear')\n",
      "y_score_LBP = clf_LBP.fit(X_train_LBP, y_train_LBP).decision_function(X_test_LBP)\n",
      "\n",
      "# Compute ROC curve and ROC area \n",
      "\n",
      "fpr_LBP, tpr_LBP, _ = roc_curve(y_test_LBP, y_score_LBP)\n",
      "roc_auc_LBP = auc(fpr_LBP, tpr_LBP)\n",
      "\n",
      "# Plot of a ROC curve for a specific class\n",
      "plt.figure()\n",
      "plt.plot(fpr_LBP, tpr_LBP, label='ROC curve (area = %0.2f)' % roc_auc_LBP)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver operating characteristic example')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}